<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>1&nbsp; Modelos lineales – Estadística II: modelos</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./Cap2-DoE.html" rel="next">
<link href="./index.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la búsqueda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Buscar"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Cap1-LM.html"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Modelos lineales</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Buscar" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Estadística II: modelos</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Buscar"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prefacio</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Cap1-LM.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Modelos lineales</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Cap2-DoE.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Diseño de experimentos</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Cap3-GLM.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Modelos lineales generalizados</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Cap4-Superv.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Análisis de supervivencia o fiabilidad</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Cap5-Seleccion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Selección de variables</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Tabla de contenidos</h2>
   
  <ul>
  <li><a href="#modelo-estadístico-de-regresión" id="toc-modelo-estadístico-de-regresión" class="nav-link active" data-scroll-target="#modelo-estadístico-de-regresión"><span class="header-section-number">1.1</span> Modelo estadístico de regresión</a>
  <ul class="collapse">
  <li><a href="#objetivos-de-la-regresión" id="toc-objetivos-de-la-regresión" class="nav-link" data-scroll-target="#objetivos-de-la-regresión"><span class="header-section-number">1.1.1</span> Objetivos de la regresión</a></li>
  <li><a href="#sec-Supuestos" id="toc-sec-Supuestos" class="nav-link" data-scroll-target="#sec-Supuestos"><span class="header-section-number">1.1.2</span> Supuestos del modelo de regresión</a></li>
  </ul></li>
  <li><a href="#lm" id="toc-lm" class="nav-link" data-scroll-target="#lm"><span class="header-section-number">1.2</span> Modelo lineal de regresión simple</a>
  <ul class="collapse">
  <li><a href="#estimación-de-los-parámetros-del-modelo" id="toc-estimación-de-los-parámetros-del-modelo" class="nav-link" data-scroll-target="#estimación-de-los-parámetros-del-modelo"><span class="header-section-number">1.2.1</span> Estimación de los parámetros del modelo</a></li>
  <li><a href="#método-de-mínimos-cuadrados" id="toc-método-de-mínimos-cuadrados" class="nav-link" data-scroll-target="#método-de-mínimos-cuadrados"><span class="header-section-number">1.2.2</span> Método de mínimos cuadrados</a></li>
  <li><a href="#método-de-máxima-verosimilitud" id="toc-método-de-máxima-verosimilitud" class="nav-link" data-scroll-target="#método-de-máxima-verosimilitud"><span class="header-section-number">1.2.3</span> Método de máxima verosimilitud</a></li>
  <li><a href="#sec-HatVarianza" id="toc-sec-HatVarianza" class="nav-link" data-scroll-target="#sec-HatVarianza"><span class="header-section-number">1.2.4</span> Estimación de la varianza del modelo</a></li>
  <li><a href="#propiedades-de-los-estimadores" id="toc-propiedades-de-los-estimadores" class="nav-link" data-scroll-target="#propiedades-de-los-estimadores"><span class="header-section-number">1.2.5</span> Propiedades de los estimadores</a></li>
  <li><a href="#sec-CH" id="toc-sec-CH" class="nav-link" data-scroll-target="#sec-CH"><span class="header-section-number">1.2.6</span> Contrastes de hipótesis</a></li>
  <li><a href="#sec-SC" id="toc-sec-SC" class="nav-link" data-scroll-target="#sec-SC"><span class="header-section-number">1.2.7</span> Suma de Cuadrados en la regresión</a></li>
  <li><a href="#bondad-de-ajuste-coeficiente-de-determinación-r2" id="toc-bondad-de-ajuste-coeficiente-de-determinación-r2" class="nav-link" data-scroll-target="#bondad-de-ajuste-coeficiente-de-determinación-r2"><span class="header-section-number">1.2.8</span> Bondad de ajuste: Coeficiente de Determinación, <span class="math inline">\(R^2\)</span></a></li>
  <li><a href="#sec-Diagnosis" id="toc-sec-Diagnosis" class="nav-link" data-scroll-target="#sec-Diagnosis"><span class="header-section-number">1.2.9</span> Diagnosis</a></li>
  <li><a href="#interpretación-de-la-recta-de-regresión" id="toc-interpretación-de-la-recta-de-regresión" class="nav-link" data-scroll-target="#interpretación-de-la-recta-de-regresión"><span class="header-section-number">1.2.10</span> Interpretación de la recta de regresión</a></li>
  <li><a href="#sec-Prediccion" id="toc-sec-Prediccion" class="nav-link" data-scroll-target="#sec-Prediccion"><span class="header-section-number">1.2.11</span> Predicción</a></li>
  <li><a href="#sec-Leverage" id="toc-sec-Leverage" class="nav-link" data-scroll-target="#sec-Leverage"><span class="header-section-number">1.2.12</span> Observaciones influyentes</a></li>
  <li><a href="#sec-Transformaciones" id="toc-sec-Transformaciones" class="nav-link" data-scroll-target="#sec-Transformaciones"><span class="header-section-number">1.2.13</span> Transformaciones</a></li>
  </ul></li>
  <li><a href="#sec-RLM" id="toc-sec-RLM" class="nav-link" data-scroll-target="#sec-RLM"><span class="header-section-number">1.3</span> Modelo lineal de regresión múltiple</a>
  <ul class="collapse">
  <li><a href="#estimación-mc" id="toc-estimación-mc" class="nav-link" data-scroll-target="#estimación-mc"><span class="header-section-number">1.3.1</span> Estimación MC</a></li>
  <li><a href="#sec-BondadAjusteMultiple" id="toc-sec-BondadAjusteMultiple" class="nav-link" data-scroll-target="#sec-BondadAjusteMultiple"><span class="header-section-number">1.3.2</span> Bondad de ajuste</a></li>
  <li><a href="#teorema-de-gauss-markov" id="toc-teorema-de-gauss-markov" class="nav-link" data-scroll-target="#teorema-de-gauss-markov"><span class="header-section-number">1.3.3</span> Teorema de Gauss-Markov</a></li>
  <li><a href="#sec-Identificabilidad" id="toc-sec-Identificabilidad" class="nav-link" data-scroll-target="#sec-Identificabilidad"><span class="header-section-number">1.3.4</span> Identificabilidad</a></li>
  <li><a href="#sec-Multicolinealidad" id="toc-sec-Multicolinealidad" class="nav-link" data-scroll-target="#sec-Multicolinealidad"><span class="header-section-number">1.3.5</span> Multicolinealidad</a></li>
  </ul></li>
  <li><a href="#sec-LM-Airquality" id="toc-sec-LM-Airquality" class="nav-link" data-scroll-target="#sec-LM-Airquality"><span class="header-section-number">1.4</span> Caso práctico: <code>airquality</code></a>
  <ul class="collapse">
  <li><a href="#exploración-de-los-datos" id="toc-exploración-de-los-datos" class="nav-link" data-scroll-target="#exploración-de-los-datos"><span class="header-section-number">1.4.1</span> Exploración de los datos</a></li>
  <li><a href="#lm-simple" id="toc-lm-simple" class="nav-link" data-scroll-target="#lm-simple"><span class="header-section-number">1.4.2</span> lm() simple</a></li>
  <li><a href="#lm-múltiple" id="toc-lm-múltiple" class="nav-link" data-scroll-target="#lm-múltiple"><span class="header-section-number">1.4.3</span> lm() múltiple</a></li>
  </ul></li>
  <li><a href="#sec-LM-Boston" id="toc-sec-LM-Boston" class="nav-link" data-scroll-target="#sec-LM-Boston"><span class="header-section-number">1.5</span> Caso práctico: <code>Boston</code></a>
  <ul class="collapse">
  <li><a href="#sec-Explotario-Boston" id="toc-sec-Explotario-Boston" class="nav-link" data-scroll-target="#sec-Explotario-Boston"><span class="header-section-number">1.5.1</span> Exploración de los datos</a></li>
  <li><a href="#lm-múltiple-1" id="toc-lm-múltiple-1" class="nav-link" data-scroll-target="#lm-múltiple-1"><span class="header-section-number">1.5.2</span> lm() múltiple</a></li>
  <li><a href="#sec-ExtensionesRLM" id="toc-sec-ExtensionesRLM" class="nav-link" data-scroll-target="#sec-ExtensionesRLM"><span class="header-section-number">1.5.3</span> Extensiones/transformaciones de la regresión múltiple</a></li>
  <li><a href="#comparación-de-modelos-mediante-anova" id="toc-comparación-de-modelos-mediante-anova" class="nav-link" data-scroll-target="#comparación-de-modelos-mediante-anova"><span class="header-section-number">1.5.4</span> Comparación de modelos mediante <code>anova()</code></a></li>
  <li><a href="#multicolinealidad-vif" id="toc-multicolinealidad-vif" class="nav-link" data-scroll-target="#multicolinealidad-vif"><span class="header-section-number">1.5.5</span> Multicolinealidad: <code>vif()</code></a></li>
  </ul></li>
  <li><a href="#resumen" id="toc-resumen" class="nav-link" data-scroll-target="#resumen"><span class="header-section-number">1.6</span> Resumen</a></li>
  <li><a href="#bibliografía" id="toc-bibliografía" class="nav-link" data-scroll-target="#bibliografía">Bibliografía</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-LM" class="quarto-section-identifier"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Modelos lineales</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<style>
body {text-align: justify}
</style>
<p>En este tema se estudian los denominados <strong>modelos lineales</strong>. El caso paradigmático es la <strong>regresión lineal <em>simple</em></strong>, caso particular del modelo de <strong>regresión lineal <em>múltiple</em></strong>. Los modelos de <strong>diseño de experimentos</strong> (que se estudian en el <a href="Cap2-DoE.html" class="quarto-xref"><span>Capítulo 2</span></a>) también son modelos lineales. En ambos modelos, la variable denominada <em>respuesta</em> debe ser cuantitativa/numérica continua, a diferencia del modelo lineal generalizado (que se estudian en el <a href="Cap3-GLM.html" class="quarto-xref"><span>Capítulo 3</span></a>).</p>
<blockquote class="blockquote">
<p><strong>Nota</strong>: Generalmente los modelos de regresión se basan en <em>estudios observacionales</em> recogiendo las variables de interés intentando no influir sobre las respuestas. Sin embargo, en un <em>experimento</em> se someten de forma deliberada los individuos a algún tratamiento (combinación de valores de variables) con el objetivo de observar sus respuestas. El <em>diseño óptimo de experimentos</em> (mi línea principal de investigación) combina el enfoque experimental con los modelos de regresión.</p>
</blockquote>
<p>Un par de buenas referencias bibliográficas para este tema son: <span class="citation" data-cites="Pena2002">Peña (<a href="#ref-Pena2002" role="doc-biblioref">2002</a>)</span>, concretamente la segunda parte, capítulos 5 a 10, y <span class="citation" data-cites="Faraway">Faraway (<a href="#ref-Faraway" role="doc-biblioref">2004</a>)</span>, que conjuga contenido matemático y práctico en los capítulos 1 a 7. Otra referencia, con un enfoque más aplicado, es el capítulo 15 “Modelización lineal” de <span class="citation" data-cites="CDRlm">Casero-Alonso y Durbán (<a href="#ref-CDRlm" role="doc-biblioref">2024</a>)</span>, <a href="https://cdr-book.github.io/cap-lm.html" class="uri">https://cdr-book.github.io/cap-lm.html</a> del libro “Fundamentos de Ciencia de Datos con R”, <span class="citation" data-cites="CDR">Fernández-Avilés y Montero (<a href="#ref-CDR" role="doc-biblioref">2024</a>)</span>, que denominamos en el texto como CDR.</p>
<section id="modelo-estadístico-de-regresión" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="modelo-estadístico-de-regresión"><span class="header-section-number">1.1</span> Modelo estadístico de regresión</h2>
<p>Parafraseando a G.E.P. Box <em>…Todos los modelos son falsos. Pero algunos son útiles…</em> Es imposible describir la realidad de forma exacta mediante un modelo, pero puede ser útil utilizar un modelo aproximado, basado en los “datos”, que permita entender y explicar el fenómeno o experimento de interés. En matemáticas un modelo es una relación matemática, no necesariamente algebraica, que permite entender el fenómeno. En estadística, a los modelos matemáticos se les añade un término de <em>error</em>, para incluir lo que la parte estructural (algebraica) no es capaz de explicar. Este término de <em>error</em> se desea <em>aleatorio</em>, <em>estocástico</em>, y tiene el papel de “cajón de sastre”.</p>
<p>El <strong>modelo lineal de regresión lineal <em>simple</em></strong> permite modelizar el comportamiento de una variable cuantitativa, denominada <em>respuesta</em> o <em>dependiente</em>, denotada por <span class="math inline">\(\mathbf{Y}\)</span>, mediante una función lineal de otra variable cuantitativa, denominada <em>explicativa</em> o <em>predictora</em>, <span class="math inline">\(\mathbf{X}\)</span>, que se supone está correlacionada con ella (<em>correlación no implica causalidad</em>). La forma habitual de expresar el modelo es: <span class="math display">\[ \mathbf{Y} = \beta_0 + \beta_1 \mathbf{X} + \epsilon, \qquad \epsilon \sim N(0, \sigma^2)\]</span></p>
<p>donde <span class="math inline">\(\mathbf{Y} = (y_1, y_2, \ldots, y_n)^\top\)</span> es el vector de las <span class="math inline">\(n\)</span> observaciones de la variable respuesta, <span class="math inline">\(\mathbf{X} = (x_1, x_2, \ldots, x_n)^\top\)</span> es el vector de las <span class="math inline">\(n\)</span> observaciones de la variable explicativa, <span class="math inline">\(\beta_i \ (i=0 \ ó \ 1)\)</span> son los coeficientes o parámetros del modelo, y <span class="math inline">\(\epsilon=(\epsilon_1, \epsilon_2, \ldots, \epsilon_n)\)</span> es el vector de errores aleatorios que convierte el modelo determinista (<span class="math inline">\(\beta_0 + \beta_1 \mathbf{X}\)</span>) en modelo estocástico. Los supuestos más habituales sobre el error son: tener media cero, varianza constante y seguir una distribución normal.</p>
<p>La generalización a varias variables <em>explicativas</em> es inmediata: <span class="math display">\[ \mathbf{Y} = \beta_0 + \beta_1 \mathbf{X}_1 + \ldots + \beta_k \mathbf{X}_k + \epsilon, \qquad \epsilon \sim N(0, \sigma^2I).\]</span> A este modelo se le denomina <strong>modelo lineal de regresión lineal <em>múltiple</em></strong>.</p>
<blockquote class="blockquote">
<p>En este contexto, cuando se habla de modelo lineal hay que distinguir entre modelo lineal <em>en las variables</em> y modelo lineal <em>en los parámetros</em>. Así:<br>
- <span class="math inline">\(\mathbf{Y}=\beta_1 \mathbf{X}_1 + \beta_2 \mathbf{X}_2 + \epsilon\)</span> es un modelo lineal en las variables y en los parámetros.<br>
- <span class="math inline">\(\mathbf{Y}=\beta_1 \mathbf{X}_1 + \beta_2 \mathbf{X}_1^2  + \epsilon\)</span> es un modelo lineal en los parámetros, pero no en la variable.<br>
- <span class="math inline">\(\mathbf{Y} = \beta_1\mathbf{X}_1^{\beta_2}  + \epsilon\)</span> es un modelo no lineal tanto en los parámetros como en la variable.<br>
En este material modelo lineal se refiere a lineal en los parámetros, sin que ello genere ambigüedad.</p>
</blockquote>
<p>Utilizando notación matricial: <span class="math display">\[\mathbf{Y} = \mathbf{X} \beta + \epsilon, , \qquad \epsilon \sim N(0, \sigma^2I) ;\]</span></p>
<p><span class="math display">\[\begin{bmatrix}
y_1 \\
y_2 \\
\vdots \\
y_n
\end{bmatrix}
=
\begin{bmatrix}
1 &amp; x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1k} \\
1 &amp; x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2k} \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
1 &amp; x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{nk}
\end{bmatrix}
\begin{bmatrix}
\beta_0 \\
\beta_1 \\
\vdots \\
\beta_k
\end{bmatrix} +
\begin{bmatrix}
\epsilon_1 \\
\epsilon_2 \\
\vdots \\
\epsilon_n \\
\end{bmatrix},\]</span> donde <span class="math inline">\(\mathbf{Y}\)</span> vuelve a ser el vector de <span class="math inline">\(n\)</span> respuestas, <span class="math inline">\(\mathbf{X}\)</span> es ahora la matriz <span class="math inline">\(n\times(k+1)\)</span> de variables explicativas, que contiene una columna de unos para incluir en el modelo el parámetro <span class="math inline">\(\beta_0\)</span> que no depende de las variables explicativas, <span class="math inline">\(\beta\)</span> es el vector de <span class="math inline">\(k+1\)</span> parámetros del modelo y <span class="math inline">\(\epsilon\)</span> vuelve a ser el vector de los términos de error aleatorios, con distribución normal, media cero y varianza constante, siendo <span class="math inline">\(I\)</span> la matriz identidad.</p>
<blockquote class="blockquote">
<p>Los modelos que se puedan expresar en la forma matricial anterior son modelos lineales.</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>Preguntas</strong><br>
En el modelo de regresión ¿tienen que ser todas las variables cuantitativas?<br>
Respuesta corta: No.<br>
Dependiendo del tipo de variables (<span class="math inline">\(\mathbf{X}\)</span> e <span class="math inline">\(\mathbf{Y}\)</span>) se tienen distintos modelos…<br>
¿Y Si hay más de una variable <span class="math inline">\(\mathbf{Y}\)</span>? Se habla de <em>regresión múltiple multivariante</em>, que se podrá ver en otra asignatura del grado.</p>
</blockquote>
<section id="objetivos-de-la-regresión" class="level3" data-number="1.1.1">
<h3 data-number="1.1.1" class="anchored" data-anchor-id="objetivos-de-la-regresión"><span class="header-section-number">1.1.1</span> Objetivos de la regresión</h3>
<ol type="1">
<li><p>Describir la estructura general entre la(s) variable(s) explicativa(s) y la respuesta, estimando y evaluando su efecto.<br>
Generalmente, este proceso es iterativo, hasta seleccionar la(s) variable(s) del mejor modelo posible (como se ve en el <a href="Cap5-Seleccion.html" class="quarto-xref"><span>Capítulo 5</span></a>).</p></li>
<li><p>Predecir observaciones futuras.</p></li>
</ol>
<p>Ambos objetivos pueden ser muy distintos! Bajo el prisma del “machine learning” suele relajarse la descripción estructural y evaluación de los efectos, dando toda la importancia a la mejor predicción posible.</p>
</section>
<section id="sec-Supuestos" class="level3" data-number="1.1.2">
<h3 data-number="1.1.2" class="anchored" data-anchor-id="sec-Supuestos"><span class="header-section-number">1.1.2</span> Supuestos del modelo de regresión</h3>
<p>Los supuestos en los que se basa el modelo de regresión expuesto son:</p>
<ul>
<li><strong>Linealidad</strong>: la relación entre la(s) variable(s) explicativa(s) y la respuesta es lineal.</li>
<li><strong>Homocedasticidad</strong> (homogeneidad de varianzas): la varianza de la variable <span class="math inline">\(\mathbf{Y}\)</span> para cada valor de <span class="math inline">\(\mathbf{X}_i\)</span> (distribución condicionada) debe ser homogénea.</li>
<li><strong>Normalidad</strong>: tanto la variable <span class="math inline">\(\mathbf{Y}\)</span> como los valores de <span class="math inline">\(\mathbf{Y}\)</span> para cada valor de <span class="math inline">\(\mathbf{X}_i\)</span> deben seguir una distribución normal.</li>
<li><strong>Independencia</strong>: cada observación de la variable <span class="math inline">\(\mathbf{Y}\)</span> debe ser independiente de las demás.</li>
</ul>
<p>Los supuestos anteriores se basan en las hipótesis de los errores:</p>
<ul>
<li>media cero: <span class="math inline">\(E[\epsilon]=0\)</span>,</li>
<li>varianza constante: <span class="math inline">\(\text{Var}[\epsilon]=\sigma^2I\)</span>,</li>
<li>distribución normal <span class="math inline">\(\epsilon \sim N(0, \sigma^2 I)\)</span></li>
<li>independencia entre errores: <span class="math inline">\(E[\epsilon_i\epsilon_j]=0\)</span></li>
</ul>
<p>Se puede encontrar más información sobre las también denominadas <em>hipótesis básicas</em> en <span class="citation" data-cites="Pena2002">Peña (<a href="#ref-Pena2002" role="doc-biblioref">2002</a>)</span> (apartados 5.2.1 y 5.2.2) y en <span class="citation" data-cites="Faraway">Faraway (<a href="#ref-Faraway" role="doc-biblioref">2004</a>)</span> (Capítulo 4)</p>
<p><strong>Residuos</strong><br>
Los <em>residuos</em>, <span class="math inline">\(u_i\)</span>, son los errores observados para los datos y el modelo escogido (realizaciones de la variable aleatoria error <span class="math inline">\(\epsilon\)</span>). Recogen toda la información que la estructura del modelo no ha sido capaz de asimilar. Es muy importante el estudio de los <em>residuos</em> para comprobar las hipótesis y supuestos anteriores y dar con ello validez al uso del modelo, como se ve en la <a href="#sec-Diagnosis" class="quarto-xref"><span>Sección 1.2.9</span></a> a nivel teórico y en los casos prácticos (<a href="#sec-LM-Airquality" class="quarto-xref"><span>Sección 1.4</span></a> y <a href="#sec-LM-Boston" class="quarto-xref"><span>Sección 1.5</span></a>).</p>
</section>
</section>
<section id="lm" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="lm"><span class="header-section-number">1.2</span> Modelo lineal de regresión simple</h2>
<p>Es habitual comenzar el estudio de los modelos lineales con el caso más sencillo, el de regresión lineal simple, para profundizar en los detalles de cada uno de los pasos del proceso de modelización, estimación, validación y predicción. Posteriormente se señalarán los aspectos que cambian al pasar a la regresión lineal múltiple, que es el caso más habitual en la práctica.</p>
<p>Partiendo de los datos <em>muestrales</em> recogidos sobre el fenómeno de interés. ¿Cómo obtener el modelo de regresión lineal simple?</p>
<ol type="1">
<li>Estructura: se deben identificar la variable respuesta (la que se pretende explicar) y la variable explicativa. Esta identificación define una forma estructural, que en este caso sencillo podría tener 2 formas:</li>
</ol>
<ul>
<li><span class="math inline">\(E(\mathbf{Y})=\beta_0 + \beta_1 \mathbf{X}\)</span>, la habitual (incluso diría “por defecto”) o</li>
<li><span class="math inline">\(E(\mathbf{Y})= \beta_1 \mathbf{X}\)</span> (proporcionalidad directa, sin término independiente).</li>
</ul>
<ol start="2" type="1">
<li><p>Estimación: con los valores muestrales recogidos <span class="math inline">\((x_i, y_i)\)</span> se obtienen las estimaciones <span class="math inline">\(\hat{\beta}_i\)</span> de los parámetros <span class="math inline">\(\beta_i\)</span> del modelo preestablecido.</p></li>
<li><p>Validación: mediante el análisis de residuos se comprueban las hipótesis que validan el uso del modelo estimado.</p></li>
<li><p>Interpretación/Inferencia: validado el modelo se interpretan las estimaciones de los parámetros y su utilidad práctica. Sólo tendrá sentido interpretar aquellos que sean significativos. También, mediante algún indicador, se dará cuenta de la bondad del modelo para explicar la variable respuesta.<br>
En este proceso, puede verse conveniente cambiar el modelo (en el caso de regresión simple, considerar otra variable explicativa, o aplicar alguna transformación) para intentar obtener un modelo que explique mejor la respuesta, con mayor bondad, por lo que se volvería al paso 1.</p></li>
<li><p>Predicción: se obtienen las predicciones necesarias u oportunas a partir del modelo considerado, teniendo cuidado con la extrapolación (y, en algunos casos, también con la interpolación).</p></li>
</ol>
<section id="estimación-de-los-parámetros-del-modelo" class="level3" data-number="1.2.1">
<h3 data-number="1.2.1" class="anchored" data-anchor-id="estimación-de-los-parámetros-del-modelo"><span class="header-section-number">1.2.1</span> Estimación de los parámetros del modelo</h3>
<p>En el caso más habitual de regresión simple: <span class="math inline">\(E(\mathbf{Y}) = \beta_0 + \beta_1\mathbf{X},\)</span> se estiman los dos parámetros del modelo: <span class="math inline">\(\beta_0\)</span>, la ordenada en el origen y <span class="math inline">\(\beta_1\)</span>, la pendiente de la recta. Intuitivamente, se buscan las estimaciones <span class="math inline">\(\hat{\beta}_0\)</span> y <span class="math inline">\(\hat{\beta}_1\)</span> que “expliquen” la relación lineal entre las dos variables, aquellas que generen las mejores predicciones posibles: <span class="math display">\[\hat{\mathbf{Y}} = \hat{\beta}_0 + \hat{\beta}_1\mathbf{X}\]</span></p>
</section>
<section id="método-de-mínimos-cuadrados" class="level3" data-number="1.2.2">
<h3 data-number="1.2.2" class="anchored" data-anchor-id="método-de-mínimos-cuadrados"><span class="header-section-number">1.2.2</span> Método de mínimos cuadrados</h3>
<p>El método por excelencia para obtener tales estimaciones es el <strong>método de mínimos cuadrados</strong> (1805 Gauss y Legendre). Consiste en minimizar los cuadrados de los <em>residuos</em>, <span class="math inline">\(u_i = y_i - \hat{y}_i = y_i - \hat{\beta}_0 + \hat{\beta}_1 x_i\)</span>, diferencia entre los valores observados y la predicción. Es decir, <span class="math display">\[\min_{\hat{\beta}_0, \hat{\beta}_1} \sum u_i^2 =
\min_{\hat{\beta}_0, \hat{\beta}_1} \sum(y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i)^2.\]</span></p>
<p>Derivando, e igualando a cero se tiene un sistema lineal de 2 ecuaciones con 2 incógnitas, denominado <strong>ecuaciones normales</strong>: <span class="math display">\[\left.\begin{align*}
\dfrac{\partial \sum u_i^2}{\partial \beta_0} &amp;= 0 \Rightarrow \sum_{i} u_i = 0 \\
\dfrac{\partial \sum u_i^2}{\partial \beta_1} &amp;= 0 \Rightarrow \sum_{i} u_i x_i = 0
\end{align*}
\right\rbrace\]</span></p>
<p>cuya solución es:</p>
<p><span class="math display">\[\begin{align*}
\hat{\beta}_1^{MC} &amp;= \rho \frac{S_y}{S_x}, \\
\hat{\beta}_0^{MC} &amp;= \bar{y} - \hat{\beta}_1^{MC} \bar{x},
\end{align*} \]</span> donde <span class="math inline">\(S_y\)</span> y <span class="math inline">\(S_x\)</span> son las desviaciones típicas muestrales de las variables <span class="math inline">\(\mathbf{Y}\)</span> y <span class="math inline">\(\mathbf{X}\)</span> y <span class="math inline">\(\rho\)</span> es el coeficiente de correlación lineal de Pearson: <span class="math display">\[\rho=\frac{S_{xy}}{S_x S_y}=\dfrac{\sum (x_i-\bar x)(y_i-\bar y )}{\sqrt{\sum (x_i-\bar x)^2 \sum (y_i-\bar y)^2}}.\]</span></p>
<p><strong>Correlación</strong><br>
En la regresión lineal simple se espera que ambas variables estén correlacionadas, así, el modelo tendrá sentido práctico. El coeficiente de correlación lineal de Pearson, <span class="math inline">\(\rho\)</span>, mide la fuerza de la relación <strong>lineal</strong> entre las dos variables. Se puede expresar en función de las medias y las desviaciones típicas de las variables:</p>
<p><span class="math display">\[\rho=\frac{1}{n-1}\sum \left( \frac{x_i-\bar{x}}{S_x} \right) \left(\frac{y_i-\bar{y}}{S_y} \right)=\frac{1}{n-1}\sum z_x \cdot z_y\]</span></p>
<p>Los valores de este coeficiente se extienden de <span class="math inline">\(-1\)</span> a <span class="math inline">\(1\)</span>, indicando ausencia de correlación cuanto más cercano a <span class="math inline">\(0\)</span>.</p>
<blockquote class="blockquote">
<p>Hay que destacar el ejemplo ilustrativo del <a href="https://en.wikipedia.org/wiki/Anscombe%27s_quartet">cuarteto de Anscombe</a>, en el que 4 conjuntos de datos presentan el mismo valor del coeficiente de correlación lineal, pero su interpretación es muy distinta en cada uno de los 4 casos.</p>
</blockquote>
<section id="interpretación-geométrica" class="level4" data-number="1.2.2.1">
<h4 data-number="1.2.2.1" class="anchored" data-anchor-id="interpretación-geométrica"><span class="header-section-number">1.2.2.1</span> Interpretación geométrica</h4>
<p>Los estimadores de mínimos cuadrados (MC) tienen una interpretación geométrica sencilla y gráficamente elocuente. Son aquellos que hacen que la recta de regresión simple minimice las distancias verticales (residuos) de toda la <em>nube de puntos</em>:</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Cap1-LM_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Ahora bien, también se puede representar el problema de MC en el espacio de las <span class="math inline">\(n\)</span> observaciones (en lugar del espacio de 2 variables), lo que proporciona una interpretación geométrica interesante (véase <span class="citation" data-cites="Faraway">Faraway (<a href="#ref-Faraway" role="doc-biblioref">2004</a>)</span> apartado 2.3). La proyección ortogonal del vector <span class="math inline">\(\mathbf{Y}=(y_1, y_2, \ldots, y_n)^\top\)</span> sobre el plano definido por los vectores <span class="math inline">\(\mathbf{1}\)</span> y <span class="math inline">\(\mathbf{X}\)</span> genera el vector de residuos <span class="math inline">\(\mathbf{u}\)</span> perpendicular a ellos y a todos los vectores del plano. Además, aplicando el teorema de Pitágoras al triangulo rectángulo resultante de la proyección (Figuras 5.11 de <span class="citation" data-cites="Pena2002">Peña (<a href="#ref-Pena2002" role="doc-biblioref">2002</a>)</span> y 2.1 de <span class="citation" data-cites="Faraway">Faraway (<a href="#ref-Faraway" role="doc-biblioref">2004</a>)</span>) proporciona una forma alternativa de obtener la fórmula de la suma de cuadrados que se ve en la <a href="#sec-SC" class="quarto-xref"><span>Sección 1.2.7</span></a>.</p>
</section>
</section>
<section id="método-de-máxima-verosimilitud" class="level3" data-number="1.2.3">
<h3 data-number="1.2.3" class="anchored" data-anchor-id="método-de-máxima-verosimilitud"><span class="header-section-number">1.2.3</span> Método de máxima verosimilitud</h3>
<p>También se pueden estimar los parámetros del modelo mediante el <strong>método de máxima verosimilitud</strong> (MV), que consiste en maximizar la función de verosimilitud <span class="math inline">\(L(\beta)\)</span>. Suponiendo normalidad: <span class="math display">\[L(\beta) = \log (2\pi)^{-n/2} \sigma^{-n} \exp\left[-\frac{\sum_{i=1}^{n} u_i^2}{2\sigma^2}\right]\]</span> En <span class="citation" data-cites="Pena2002">Peña (<a href="#ref-Pena2002" role="doc-biblioref">2002</a>)</span>, apartado 5.4.1, se puede ver el detalle de la obtención de los estimadores máximo verosímiles.</p>
<p>Bajo el supuesto de normalidad, los estimadores MC coinciden con los MV, es decir, los estimadores que minimizan la suma de cuadrados de los residuos, también maximizan la probabilidad de los datos observados. Basta observar la fórmula de la verosimilitud escrita arriba.</p>
</section>
<section id="sec-HatVarianza" class="level3" data-number="1.2.4">
<h3 data-number="1.2.4" class="anchored" data-anchor-id="sec-HatVarianza"><span class="header-section-number">1.2.4</span> Estimación de la varianza del modelo</h3>
<p>También es necesario estimar la varianza del modelo. Utilizando el método de máxima verosimilitud se llega a: <span class="math display">\[\hat{\sigma}^2_{MV}=\dfrac{\sum u_i^2 }{n},\]</span> es decir, es la varianza de los residuos (la dividida por <span class="math inline">\(n\)</span>).</p>
<p>Ahora bien, los <span class="math inline">\(n\)</span> residuos no son independientes, se pierden 2 grados de libertad al tener que estimar los dos parámetros de la recta de regresión. Por ello, se define el estimador denominado <em>varianza residual</em>: <span class="math display">\[\hat S_R^2=\dfrac{\sum u_i^2 }{n-2}.\]</span> En la práctica se suele obtener su raíz cuadrada, <span class="math inline">\(\hat S_R\)</span>, denominada <em>error estándar residual</em>.</p>
</section>
<section id="propiedades-de-los-estimadores" class="level3" data-number="1.2.5">
<h3 data-number="1.2.5" class="anchored" data-anchor-id="propiedades-de-los-estimadores"><span class="header-section-number">1.2.5</span> Propiedades de los estimadores</h3>
<p>El estudio de las propiedades de los estimadores obtenidos resulta de interés para la posterior inferencia. Aquí se mencionan algunas propiedades. El lector interesado puede ampliar información, por ejemplo, en <span class="citation" data-cites="Pena2002">Peña (<a href="#ref-Pena2002" role="doc-biblioref">2002</a>)</span> (la Tabla 5.3, página 264, contiene un buen resumen)</p>
<p>Antes de ello, la ecuación de la recta de regresión también se suele expresar en la forma punto-pendiente: <span class="math display">\[(y - \bar{y}) = \hat{\beta}_1 (x - \bar{x}), \]</span> de donde se deduce inmediatamente que el punto <span class="math inline">\((\bar x, \bar y)\)</span>, pertenece a la recta estimada. Tal punto se conoce como <em>centroide</em>, centro de gravedad de la nube de puntos.</p>
<p>Sobre <span class="math inline">\(\hat \beta_1\)</span>, la pendiente estimada de la recta. Esta pendiente se puede obtener como una media ponderada de pendientes de las rectas que pasan por cada punto y por centroide. Tal ponderación está relacionada con el <em>leverage</em> (véase <a href="#sec-Leverage" class="quarto-xref"><span>Sección 1.2.12</span></a>) e implica que los puntos con valores de <span class="math inline">\(x\)</span> más alejados a la media tienen más influencia sobre la estimación de <span class="math inline">\(\beta_1\)</span>, más cuanto menos puntos sean. También se puede ver que el estimador sigue una distribución normal, si la variable respuesta sigue una distribución normal, concretamente, <span class="math display">\[\hat \beta_1 \sim N(\beta_1, \dfrac{\sigma^2}{nS_x^2}).\]</span> Por lo tanto, es insesgado (asumiendo la linealidad, independientemente de la normalidad) y su varianza disminuirá (aumentará la precisión de <span class="math inline">\(\hat\beta_1\)</span>), bien al aumentar el tamaño de muestra, <span class="math inline">\(n\)</span>, o al aumentar la dispersión de los valores de <span class="math inline">\(x\)</span>, <span class="math inline">\(S_x^2\)</span>. Como <span class="math inline">\(\sigma^2\)</span> es desconocida, se considera en su lugar la varianza residual <span class="math inline">\(\hat S_R^2\)</span>.</p>
<p>Sobre <span class="math inline">\(\hat \beta_0\)</span>, mencionar que es el parámetro de la ordenada en el origen (intersección de la recta con el eje <span class="math inline">\(y\)</span>) y su importancia se encuentra en un segundo plano respecto a <span class="math inline">\(\hat \beta_1\)</span>. También se puede ver como una combinación lineal de valores de la variable respuesta, por lo que seguirá una distribución normal (como la variable respuesta), concretamente, <span class="math display">\[\hat \beta_0 \sim N \left( \beta_0, \dfrac{\sigma^2}{n} \left( 1+ \dfrac{\bar x^2}{S_x^2}\right) \right).\]</span> También es insesgado, y su varianza está multiplicada por <span class="math inline">\(\bar x^2\)</span>, lo que supone mayor impacto cuando mayor sea el valor de <span class="math inline">\(\bar x\)</span>.</p>
<p>Además, ambos estimadores están correlacionados: <span class="math display">\[\text{Cov}(\hat{\beta}_0, \hat{\beta}_1) = -\dfrac{\bar{x}\sigma^2}{nS_x^2}\]</span> Por lo tanto, cuando <span class="math inline">\(\bar{x}&gt;0\)</span>, <span class="math inline">\(\hat{\beta}_0\)</span> y <span class="math inline">\(\hat{\beta}_1\)</span> están negativamente correlados.</p>
<p>Respecto a la varianza residual, se tiene que <span class="math inline">\(\hat S_R^2\)</span> es un estimador insesgado de <span class="math inline">\(\sigma^2\)</span>, dado que <span class="math display">\[\dfrac{(n-2) \hat S_R^2}{\sigma^2} \sim \chi^2_{n-2}.\]</span></p>
</section>
<section id="sec-CH" class="level3" data-number="1.2.6">
<h3 data-number="1.2.6" class="anchored" data-anchor-id="sec-CH"><span class="header-section-number">1.2.6</span> Contrastes de hipótesis</h3>
<p>Conocidas las distribuciones en el muestro de los estimadores, podemos plantear contrastes de hipótesis sobre ellos. En una regresión lineal simple, realizar un contraste de hipótesis sobre el parámetro <span class="math inline">\(\beta_1\)</span> asociado a la variable explicativa, es equivalente al contraste de hipótesis sobre el coeficiente de correlación lineal de Pearson entre dicha variable y la respuesta, <span class="math inline">\(\rho\)</span>: <span class="math display">\[\left. \begin{array}{ll}
H_0: \beta_1 = 0 \\
H_1: \beta_1 \neq 0
\end{array} \right\rbrace
\qquad \equiv  \qquad
\left. \begin{array}{ll}
H_0: \rho = 0 \\
H_1: \rho \neq 0
\end{array} \right\rbrace\]</span></p>
<p>Para parejas de variables normales e incorreladas se cumple que: <span class="math display">\[\rho\sqrt{\frac{n-2}{1-\rho^2}} \sim t_{n-2}
\qquad \equiv \qquad
\dfrac{\hat \beta_i - \beta_i}{\hat s(\hat \beta_i)} \sim t_{n-2}\]</span> donde <span class="math inline">\(\hat s(\hat \beta_i)\)</span>, es el estimador de la desviación típica del estimador. Esto también se cumple de forma aproximada si las variables son no normales y si los tamaños de muestra son “grandes” (o no demasiado pequeños). Y de aquí podemos determinar la significación de la estimación del parámetro <span class="math inline">\(\hat \beta_1\)</span> (de una correlación). El p-valor nos dará la fuerza de dicha significación.</p>
</section>
<section id="sec-SC" class="level3" data-number="1.2.7">
<h3 data-number="1.2.7" class="anchored" data-anchor-id="sec-SC"><span class="header-section-number">1.2.7</span> Suma de Cuadrados en la regresión</h3>
<p>Al contraste de hipótesis anterior también puede llegarse desde otro punto de vista. Los residuos, distancias verticales entre cada uno de los puntos, <span class="math inline">\((x_i,y_i)\)</span>, y la recta de regresión, expresan el error aleatorio del modelo. ¿Hasta qué punto es más importante el efecto de la variable <span class="math inline">\(\mathbf{X}\)</span> sobre la variable <span class="math inline">\(\mathbf{Y}\)</span> que el error de los residuos?</p>
<p>Si las variables <span class="math inline">\(\mathbf{X}\)</span> e <span class="math inline">\(\mathbf{Y}\)</span> no estuviesen relacionadas, no aportaría información sobre <span class="math inline">\(\mathbf{Y}\)</span> conocer los valores de <span class="math inline">\(\mathbf{X}\)</span>. La mejor predicción que podríamos hacer sería predecir <span class="math inline">\(\mathbf{Y}\)</span> con su media, <span class="math inline">\(\bar{\mathbf{Y}}\)</span>, sin tener en cuenta el valor de <span class="math inline">\(\mathbf{X}\)</span>. Este modelo (<span class="math inline">\(\beta_1 = 0\)</span>), el más sencillo, es el que vamos a intentar falsar.</p>
<p>El estudio de la <em>variabilidad</em> (<em>información</em>) de la variable respuesta nos aportará evidencias que nos permitan (o no) rechazar <span class="math inline">\(H_0: \beta_1 = 0\)</span> (falsarla) y asumir la hipótesis alternativa, <span class="math inline">\(H_1 : \beta_1 \neq 0\)</span>.</p>
<p><span class="math display">\[SC_{total}=SC_y=\sum (y_i-\bar{y})^2\]</span></p>
<p><span class="math inline">\(SC_{total}\)</span> es el numerador de la habitual varianza muestral aplicada a <span class="math inline">\(y\)</span>. Se puede calcular multiplicando dicha varianza por los grados de libertad <span class="math inline">\(n-1\)</span>.</p>
<p>Matemáticamente se puede descomponerse en <span class="math inline">\(SC_{regresion}\)</span> y <span class="math inline">\(SC_{residual}\)</span>.</p>
<p><span class="math display">\[SC_{total}=SC_{regresion}+SC_{residual}\]</span> <span class="math display">\[\sum (y-\bar{y})^2={\sum (\hat{y}-\bar{y})^2}+\sum (y-\hat{y})^2\]</span></p>
<p>Estudiamos los grados de libertad (gl) al calcular cada uno de los términos:</p>
<ul>
<li>Para <span class="math inline">\(SC_{total}\)</span> “gastamos” <span class="math inline">\(1\)</span> gl al dar la media, <span class="math inline">\(\bar{y}\)</span>, por lo que tiene <span class="math inline">\(n-1\)</span> gl.</li>
<li>Los gl de los residuos son <span class="math inline">\(n-2\)</span>, necesitamos <span class="math inline">\(\hat{\beta}_0\)</span> y <span class="math inline">\(\hat{\beta}_1\)</span> para calcular <span class="math inline">\(SC_{residual}\)</span>.<br>
</li>
<li>Con lo que nos queda <span class="math inline">\(1\)</span> gl para la suma de cuadrados de la regresión <span class="math inline">\(SC_{regresion}\)</span>. “Gastamos” <span class="math inline">\(1\)</span> gl con el parámetro extra que hemos estimado <span class="math inline">\(\hat{\beta}_1\)</span>, la pendiente.</li>
</ul>
<p>Por último, se promedia cada suma de cuadrados por sus respectivos grados de libertad (SCM: Suma de Cuadrados Media), en definitiva, calculamos varianzas.</p>
<p>Nunca seremos capaces de realizar predicciones perfectas (<em>todos los modelos son falsos</em>), pero estamos interesados en comparar el efecto de <span class="math inline">\(\mathbf{X}\)</span> sobre <span class="math inline">\(\mathbf{Y}\)</span> con el error aleatorio (residual):</p>
<p><span class="math display">\[\frac{\text{Efecto de X sobre Y}}{\text{Error Aleatorio}}=\frac{\text{Varianza de la Regresión}}{\text{Varianza Error}}=\frac{SCM_{regresion}}{SCM_{error}}=F \sim F_{1,n-2}\]</span></p>
<p>Esto se conoce en estadística como un <strong>Análisis de la Varianza, ANOVA</strong> (que se ve más en profundidad en el <a href="Cap2-DoE.html" class="quarto-xref"><span>Capítulo 2</span></a>).</p>
<p>Para que podamos falsar <span class="math inline">\(H_0\)</span>, la Varianza de la Regresión debe ser mayor que la Varianza del Error, cuanto más grande mejor. Si ambas son próximas se concluye que <span class="math inline">\(\beta_1\)</span> puede ser 0.</p>
<p>Se compara entonces el estadístico F obtenido de dividir las dos varianzas con una distribución F con los grados de libertad correspondientes, <span class="math inline">\(1\)</span> en el numerador y <span class="math inline">\(n-2\)</span> en el denominador. Calculando el p-valor se podrá rechazar (o no) la hipótesis nula, concluyendo (o no) que <span class="math inline">\(\beta_1\)</span> es significativamente distinto de 0.</p>
<p>Es importante resaltar aquí el supuesto de linealidad. No rechazar <span class="math inline">\(H_0\)</span> no implica necesariamente que <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span> sean independientes, podrían estar relacionadas de forma no lineal, y la aproximación lineal podría no ser significativa.</p>
<p>En <span class="citation" data-cites="Pena2002">Peña (<a href="#ref-Pena2002" role="doc-biblioref">2002</a>)</span>, Apartado 5.6.2, se descompone las desviaciones de los datos (usando notación matricial) en dos componentes <em>ortogonales</em>. Por el teorema de Pitágoras se llega a la descomposición de la variabilidad descrita aquí. Además, en el Apéndice 5B, se dan detalles sobre la “Deducción de las distribuciones de sumas de cuadrados”.</p>
</section>
<section id="bondad-de-ajuste-coeficiente-de-determinación-r2" class="level3" data-number="1.2.8">
<h3 data-number="1.2.8" class="anchored" data-anchor-id="bondad-de-ajuste-coeficiente-de-determinación-r2"><span class="header-section-number">1.2.8</span> Bondad de ajuste: Coeficiente de Determinación, <span class="math inline">\(R^2\)</span></h3>
<p>Por la descomposición mencionada anteriormente, <span class="math inline">\(SC_{total}=SC_{regresion}+SC_{residual}\)</span>, la proporción de variabilidad explicada por la regresión, respecto al total, es un indicador de la bondad de la regresión:</p>
<p><span class="math display">\[\frac{SC_{regresion}}{SC_{total}} = R^2,\]</span></p>
<p>lo que se conoce como <em>coeficiente de determinación</em>, <span class="math inline">\(R^2\)</span>. Como proporción, puede tomar valores entre <span class="math inline">\(0\)</span> y <span class="math inline">\(1\)</span>, evitando así la dependencia de las unidades de medida. Suele expresarse en porcentaje.</p>
<p>La siguiente figura permite ilustrar el concepto de bondad de ajuste.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Cap1-LM_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>En la gráfica de la izquierda se tiene un buen ajuste de la recta de regresión, que produce un <span class="math inline">\(R^2\)</span> elevado. Mientras que en la gráfica de la derecha el <span class="math inline">\(R^2\)</span> es próximo a cero, indicando que el conocimiento de los valores de <span class="math inline">\(\mathbf{X}\)</span> aporta casi nula información sobre los valores de variable <span class="math inline">\(\mathbf{Y}\)</span>. Para más énfasis, en la imagen de la izquierda se muestra la variabilidad total de <span class="math inline">\(\mathbf{Y}\)</span> frente a la variabilidad que tiene <span class="math inline">\(\mathbf{Y}\)</span> para casi cualquier valor de <span class="math inline">\(\mathbf{X}\)</span>.</p>
<p><strong>Obtención del coeficiente</strong><br>
En el caso de la regresión lineal <em>simple</em>, <span class="math inline">\(R^2\)</span> coincide con el cuadrado del coeficiente de correlación, <span class="math inline">\(\rho\)</span> (véase <span class="citation" data-cites="Pena2002">Peña (<a href="#ref-Pena2002" role="doc-biblioref">2002</a>)</span>, apartado 5.7.1, donde se dan detalles de cómo llegar al coeficiente de correlación a partir del de determinación, o a partir de la varianza residual).</p>
</section>
<section id="sec-Diagnosis" class="level3" data-number="1.2.9">
<h3 data-number="1.2.9" class="anchored" data-anchor-id="sec-Diagnosis"><span class="header-section-number">1.2.9</span> Diagnosis</h3>
<p>La diagnosis consiste en comprobar los supuestos básicos del modelo (<a href="#sec-Supuestos" class="quarto-xref"><span>Sección 1.1.2</span></a>). Recordemos: linealidad, homocedasticidad, normalidad e independencia.</p>
<p>En la regresión simple, los supuestos de linealidad y homocedasticidad se pueden comprobar visualmente acudiendo al diagrama de dispersión. En la regresión múltiple, no es tan directo. Se acude directamente a los gráficos de diagnóstico, basados en los residuos del modelo, para comprobar las hipótesis. Con la ayuda de <code>R</code> será bastante sencillo obtener tales gráficos. Por lo que, en la práctica, se comprueban las hipótesis (y alguna característica más) en ellos. Ahora bien, el supuesto de independencia podría incumplirse por construcción, por ejemplo, si se tienen datos temporales.</p>
<p>Un enfoque ligeramente distinto sobre la diagnosis se encuentra en <span class="citation" data-cites="Faraway">Faraway (<a href="#ref-Faraway" role="doc-biblioref">2004</a>)</span>, que divide los problemas potenciales de la regresión estimada en 3 categorías:</p>
<ul>
<li>error: se asume que los errores son independientes, tienen varianza constante y son normalmente distribuidos.</li>
<li>modelo: se asume que la parte estructural del modelo es correcta, es decir, que la relación entre las variables es lineal.</li>
<li>observaciones inusuales: en ocasiones unas pocas observaciones no se ajustan al modelo, o cambian/influyen demasiado en el modelo.</li>
</ul>
<p>Además indica que las técnicas gráficas de diagnóstico son más flexibles, pero mucho más difíciles de interpretar, que las de contrastes, que son sencillas y directas (no requieren de intuición y podrían parecer más precisas), pero no permiten una visualización general del problema. La diagnosis gráfica de los residuos permiten detectar problemas, revelar estructuras ocultas que es imposible vislumbrar con los contrastes, lo que da pistas para solucionar los problemas de la regresión, llevando la modelización a un proceso iterativo, con cierto aire artesanal. Por ello, predomina un enfoque gráfico para el diagnóstico, acudiendo a los contrastes como complemento para confirmar lo observado en los gráficos. En ocasiones los gráficos pueden ser ambiguos, pero al menos permiten verificar que no hay grandes desviaciones de los supuestos del modelo.</p>
<section id="linealidad" class="level4" data-number="1.2.9.1">
<h4 data-number="1.2.9.1" class="anchored" data-anchor-id="linealidad"><span class="header-section-number">1.2.9.1</span> Linealidad</h4>
<p>Como se ha comentado, el modelo asume una estructura lineal en la relación entre el predictor y la respuesta, que puede observarse fácilmente con el gráfico de dispersión entre ambas variables.</p>
<p>Ahora bien, en la práctica, cuando se estima el modelo con software, es fácil tener los residuos y comprobar esta hipótesis en el correspondiente gráfico de diagnóstico. Concretamente, a partir del gráfico de residuos frente a valores estimados por el modelo, para cada valor observado. En líneas generales, si la relación lineal es la correcta se observará aleatoriedad, valores dispersos entorno al 0 (verticalmente), sin tendencias ni otros patrones marcados (véase el gráfico del apartado siguiente de <em>Homocedasticidad</em>).</p>
<p>El <strong>contraste de linealidad</strong> es el de la tabla ANOVA, por lo que no se entrará aquí en más detalles de los ya vistos.</p>
</section>
<section id="homocedasticidad" class="level4" data-number="1.2.9.2">
<h4 data-number="1.2.9.2" class="anchored" data-anchor-id="homocedasticidad"><span class="header-section-number">1.2.9.2</span> Homocedasticidad</h4>
<p>Los residuos deben tener varianza constante, homocedasticidad, con respecto a los valores de la variable <span class="math inline">\(x\)</span>, en el caso de regresión simple (por lo que se puede comprobar en el gráfico de dispersión entre <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>). La falta de homocedasticidad invalida el uso de los estimadores MC/MV pues implica distinta precisión en las estimaciones.</p>
<p><strong>Análisis gráfico</strong><br>
El gráfico de diagnóstico apropiado para observar la homocedasticidad o heterocedasticidad es el de residuos frente a valores estimados por el modelo (el mismo que para la linealidad, que es también válido para el caso de regresión múltiple). De nuevo se desea observar aleatoriedad, ausencia de patrones.</p>
<p>En el siguiente gráfico se pueden ver ejemplos simulados de distintas situaciones, que se interpretan de una forma clara. Pero la realidad supera la ficción… Se necesita cierta experiencia para no cometer equivocaciones al interpretar gráficos de residuos.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Cap1-LM_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Lo deseable en este gráfico es encontrar una nube de puntos dispersos (y simétricos, mirando verticalmente) alrededor de 0, sin ningún patrón aparente (como en el primer gráfico). Si se observa un patrón, como una forma cónica (segundo gráfico) o una tendencia (como la no lineal del tercer gráfico), puede indicar problemas de heterocedasticidad (varianza no constante) o no linealidad en el modelo. Estas dos últimas situaciones dan pistas de las posibles acciones a tomar sobre los datos, como transformar la variable <span class="math inline">\(x\)</span> o <span class="math inline">\(y\)</span> para conseguir homocedasticidad, o incluir algún término no lineal en la variable <span class="math inline">\(x\)</span> (manteniendo el modelo lineal en los parámetros). Por su parte, el primer gráfico permitiría validar gráficamente el supuesto de homocedasticidad.</p>
<p>Como se ve en los casos prácticos (<a href="#sec-LM-Airquality" class="quarto-xref"><span>Sección 1.4</span></a> y <a href="#sec-LM-Boston" class="quarto-xref"><span>Sección 1.5</span></a>), se suele también comprobar la homocedasticidad en el gráfico de la raíz cuadrada del valor absoluto de los residuos <em>estandarizados</em> (véase <a href="#sec-Leverage" class="quarto-xref"><span>Sección 1.2.12</span></a>) frente a los valores estimados. Al tomar el valor absoluto se aumenta la resolución para detectar la falta de homocedasticidad. Ahora bien, no permite la comprobación de la nolinealidad.</p>
<p>Una alternativa, más elaborada, es la propuesta de <span class="citation" data-cites="Faraway">Faraway (<a href="#ref-Faraway" role="doc-biblioref">2004</a>)</span>: dibujar los residuos frente a cada una de las <span class="math inline">\(x_i\)</span> -en caso de regresión múltiple-. Para todas la variables del conjunto de datos, tanto las incluidas en el modelo, como las no incluidas, mirando en estas últimas si existe alguna relación que indique la necesidad de incluirla en el modelo.</p>
<p><strong>Contrastes</strong><br>
Los contrastes para detectar heterocedasticidad, tienen una hipótesis nula clara: <span class="math display">\[H_0: \sigma^2 = \text{cte}, \]</span> Pero dependen de la hipótesis alternativa especificada. Así, el contraste puede detectar bien un tipo específico de heterocedasticidad, pero no tener <em>potencia</em> suficiente para otros.</p>
<p>De entre los distintos contrastes para comprobar la homocedasticidad destacan, el contraste de Bartlett y el de Levene, que evalúan la hipótesis nula de igualdad de varianzas entre <span class="math inline">\(k\)</span> grupos. Los estadístico de contraste se pueden encontrar en la página web del <em>NIST/SEMATECH e-Handbook of Statistical Methods</em>, concretamente: <a href="https://www.itl.nist.gov/div898/handbook/eda/section3/eda357.htm">contraste de Bartlett</a> y <a href="https://www.itl.nist.gov/div898/handbook/eda/section3/eda35a.htm">contraste de Levene</a>, respectivamente. El estadístico de Bartlett sigue aproximadamente una distribución <span class="math inline">\(\chi^2\)</span> con <span class="math inline">\(k - 1\)</span> grados de libertad bajo <span class="math inline">\(H_0\)</span>. Mientras que el de Levene sigue aproximadamente una distribución <span class="math inline">\(F\)</span> con <span class="math inline">\(k-1\)</span> y <span class="math inline">\(n-k\)</span> grados de libertad. En ambos casos, se rechazará la homocedasticidad si se obtienen p-valores pequeños, habitualmente inferiores a 0.05.</p>
</section>
<section id="normalidad" class="level4" data-number="1.2.9.3">
<h4 data-number="1.2.9.3" class="anchored" data-anchor-id="normalidad"><span class="header-section-number">1.2.9.3</span> Normalidad</h4>
<p>Los residuos también deben seguir una distribución normal, para justificar el uso de estimadores MC/MV.</p>
<p>El gráfico apropiado para evaluarlo es el denominado Q-Q plot (gráfico Cuantil-Cuantil): un diagrama de dispersión de los cuantiles de los residuos frente a los cuantiles de la distribución normal (con la misma media y desviación típica de los residuos). La interpretación, como diagrama de dispersión, es bien sencilla, los residuos siguen una distribución normal cuanto más se alineen los puntos del diagrama sobre una linea recta “guía” (y más diagonal sea dicha “guía”). Se incumple la normalidad generalmente por las colas, con puntos que se alejan ostensiblemente de la recta “guía”. Por ejemplo, es típico observar curvatura en forma de S, indicando que los residuos tiene colas más ligeras que la distribución normal, o curvatura en forma de U indicando que siguen otra distribución.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Cap1-LM_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p><strong>Contrastes</strong><br>
Para completar la comprobación gráfica, se acude a los contrastes de normalidad. El más difundido es del de Shapiro-Wilk, basado precisamente en el gráfico Q-Q, y considerado uno de los que más <em>potencia</em> poseen para contrastar normalidad. <span class="math display">\[\left. \begin{array}{ll}
H_0: \text{los residuos provienen de una distribución normal} \\
H_1: \hspace{1.4cm}\text{... no provienen...}
\end{array} \right\rbrace\]</span> Para más información sobre el test de Shapiro-Wilk se puede consultar también la web del <em>NIST/SEMATECH e-Handbook of Statistical Methods</em>: <a href="https://www.itl.nist.gov/div898/handbook/prc/section2/prc213.htm">Shapiro-Wilk test</a>. En este caso, el estadístico de contraste no sigue una distribución de probabilidad conocida y sus probabilidades se han calculado mediante simulaciones por el método de Monte Carlo.</p>
</section>
<section id="sec-Independencia" class="level4" data-number="1.2.9.4">
<h4 data-number="1.2.9.4" class="anchored" data-anchor-id="sec-Independencia"><span class="header-section-number">1.2.9.4</span> Independencia</h4>
<p>La independencia es un supuesto que puede comprobarse con los gráficos de residuos, pero que puede incumplirse desde el planteamiento del problema, de la recogida de datos, etc. sin necesidad de llegar al análisis de residuos, en el que incluso podría no quedar reflejado el incumplimiento.</p>
<p>Para comprobar la independencia temporal de los datos se visualizará el gráfico de residuos frente al orden en la toma de datos (si se dispone de ello), o, en su defecto, en el orden que se tengan los datos (que podrían haber sido ordenados, lo que impediría su correcto análisis).</p>
<p><strong>Contrastes</strong><br>
Como en los anteriores supuestos, se suele acudir a contrastes para completar el análisis de independencia. El más utilizado es el de <strong>Durbin-Watson</strong>, que comprueba la presencia de autocorrelación (relación temporal entre los residuos). <span class="math display">\[\left. \begin{array}{ll}
H_0: \text{los residuos no tienen correlación temporal} \\
H_1: \text{los residuos siguen un proceso autorregresivo de primer orden, } AR(1) \end{array} \right\rbrace\]</span> Más información en <a href="https://en.wikipedia.org/wiki/Durbin%E2%80%93Watson_statistic">Estadístico de Durbin–Watson</a>.</p>
</section>
<section id="soluciones" class="level4" data-number="1.2.9.5">
<h4 data-number="1.2.9.5" class="anchored" data-anchor-id="soluciones"><span class="header-section-number">1.2.9.5</span> Soluciones</h4>
<p>Como se ha comentado, la comprobación de los supuestos mediante los gráficos de residuos, a la par que pueden conducir a rechazar uno o varios de ellos, pueden proporcionar pistas para su solución.</p>
<p>Lo primero que suele saltar a la vista en el análisis gráfico es la presencia de <strong>observaciones atípicas</strong>, que contribuyen a la falta de linealidad, de homocedasticidad, ambas… Lo apropiado es analizar el impacto de dichas observaciones, por ejemplo, comparando los modelos estimados con tales observaciones o sin ellas. Para ello, se han desarrollado medidas como el <em>leverage</em> y la <em>distancia de Cook</em>, para averiguar la <em>influencia</em> de las observaciones (sean atípicas o no) en la regresión (véase <a href="#sec-Leverage" class="quarto-xref"><span>Sección 1.2.12</span></a>). El resultado de este análisis puede llevar a detectar errores de medición, o que la definición funcional (como forma lineal) del problema no es la adecuada.</p>
<p>Otra posible solución para obtener linealidad y/o homocedasticidad es realizar <strong>transformaciones</strong> en las variables, bien <span class="math inline">\(y\)</span>, bien <span class="math inline">\(x\)</span>, o ambas (véase <a href="#sec-Transformaciones" class="quarto-xref"><span>Sección 1.2.13</span></a>). Por ejemplo, la relación entre la variable <span class="math inline">\(y\)</span> y la <span class="math inline">\(x\)</span> podría ser exponencial, por lo que, tomando como respuesta <span class="math inline">\(\log(y)\)</span> se tendrá linealidad. Sobre la heterocedasticidad, en ocasiones se da por la dependencia de la varianza de <span class="math inline">\(y\)</span> respecto de <span class="math inline">\(x\)</span>. Si se dividen las observaciones por la estructura que provoque <span class="math inline">\(x\)</span> en la varianza, se tendrá un modelo homocedástico. En la práctica, el gráfico de residuos frente a valores estimados puede dar pistas sobre la transformación a realizar. Pero, se suelen intentar varias transformaciones, pues es un arte encontrar la transformación más adecuada (la intuición y la experiencia pueden ayudar).</p>
<p>Un caso más complejo de intuir es la introducción de variables para conseguir linealidad, bien puede ser, términos polinomiales de la misma variable, lo que conduce a una regresión polinómica lineal (véase <a href="#sec-ExtensionesRLM" class="quarto-xref"><span>Sección 1.5.3</span></a>), o bien, se pueden añadir otras variables, lo que lleva a un modelo lineal de regresión múltiple (véase <a href="#sec-RLM" class="quarto-xref"><span>Sección 1.3</span></a>). Otras opciones de resolver los problemas por incumplimiento de los supuestos básicos pasan por acudir a regresión no paramétrica (que se escapa del alcance de este material) o, en el caso de la heterocedasticidad, aprovechar si se conoce la estructura de varianza para utilizar el método de mínimos cuadrados ponderados.</p>
</section>
</section>
<section id="interpretación-de-la-recta-de-regresión" class="level3" data-number="1.2.10">
<h3 data-number="1.2.10" class="anchored" data-anchor-id="interpretación-de-la-recta-de-regresión"><span class="header-section-number">1.2.10</span> Interpretación de la recta de regresión</h3>
<p>Una vez estimada y validada la recta de regresión, si es significativa, estadísticamente hablando, se puede pasar a interpretar los coeficientes/parámetros, si tienen un sentido práctico (y el análisis de residuos que se ve más adelante no invalida los supuestos en los que se basa).</p>
<p>La interpretación generalmente más importante es la de <span class="math inline">\(\hat \beta_1\)</span> dado que recoge el efecto sobre la variable <span class="math inline">\(y\)</span> de la variación de una unidad de la variable explicativa <span class="math inline">\(x\)</span>. Su interpretación debe hacerse acorde a las unidades en la que esté recogida la variable (no es lo mismo que, si es una medida de temperatura, se haya medido en ºC que en ºK, o si es de tiempo que se mida en segundos o en días). Así el impacto sobre la respuesta del cambio de <span class="math inline">\(1\)</span> ºC (o de <span class="math inline">\(1\)</span> s) será de una magnitud muy distinta al cambio de 100ºC (<span class="math inline">\(1\)</span> hora). Es más, el valor de <span class="math inline">\(\hat \beta_1\)</span> se podría aumentar o disminuir haciendo cambios de escala en las variables <span class="math inline">\(y\)</span> y <span class="math inline">\(x\)</span>.</p>
<p>¿Y qué pasa si en lugar de tener sólo una variable tenemos más variables? En el apartado de regresión múltiple (<a href="#sec-RLM" class="quarto-xref"><span>Sección 1.3</span></a>), se ve el cambio que supone el tener varias variables explicativas, en la interpretación de las estimaciones de los parámetros.</p>
<p>La interpretación de la estimación <span class="math inline">\(\hat \beta_0\)</span> es el del valor medio en ausencia del valor de la <span class="math inline">\(x\)</span>, que en ciertas ocasiones no pertenece al rango de variación de la variable <span class="math inline">\(x\)</span> o puede no tener sentido (por ejemplo si la variable <span class="math inline">\(x\)</span> recoge la edad de los individuos, puede que no tenga sentido la media a <span class="math inline">\(0\)</span> años).</p>
<p>Si la recta no fuese significativa, no implica que no haya relación entre <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>, quizá la relación es no lineal (como se ve en <a href="#sec-Diagnosis" class="quarto-xref"><span>Sección 1.2.9</span></a>) o quizá el rango escogido para la <span class="math inline">\(x\)</span> no es el idóneo para observar su influencia sobre la <span class="math inline">\(y\)</span> (quizá es demasiado estrecho). Pero, como se señala en <span class="citation" data-cites="Pena2002">Peña (<a href="#ref-Pena2002" role="doc-biblioref">2002</a>)</span>, para encontrar relaciones causales hay que acudir al diseño de experimentos (<a href="Cap2-DoE.html" class="quarto-xref"><span>Capítulo 2</span></a>), porque en un experimento se puede intentar controlar los valores de la variable <span class="math inline">\(x\)</span> que se cree que influyen sobre la <span class="math inline">\(y\)</span> y aleatorizar el resto de variables para “repartir” su impacto sobre la respuesta. Mientras que si los datos son observacionales sólo se puede deducir covariación, pero no causalidad, como que haya más criminalidad en las ciudades con más policías. Aquí la causa es una tercera variable, el tamaño de la ciudad. Reducir el número de policías ¡no causaría una reducción de la criminalidad!</p>
</section>
<section id="sec-Prediccion" class="level3" data-number="1.2.11">
<h3 data-number="1.2.11" class="anchored" data-anchor-id="sec-Prediccion"><span class="header-section-number">1.2.11</span> Predicción</h3>
<p>Uno de los objetivos de la modelización es la posibilidad de poder predecir valores de la variable respuesta conocidos los valores de la variable explicativa.</p>
<p>Dichas predicciones pueden ser de dos tipos, predicciones medias, para la media de un conjunto de observaciones con el mismo valor del predictor, o predicciones individuales, para un sólo valor de la variable respuesta para un valor del predictor. Realmente, la predicción será la misma, la dada por la recta de regresión, pero la incertidumbre o precisión de dicha estimación, esto es, el intervalo de confianza, será distinto según se trate de la predicción de una media o un valor individual. Los intervalos de confianza para las predicciones individuales son más amplios que para los intervalos de confianza de la recta.</p>
<p>Para todo ello es fundamental estudiar el error estándar de la pendiente y de la ordenada en el origen (en el caso de regresión lineal).</p>
<section id="errores-estándar-de-los-estimadores" class="level4" data-number="1.2.11.1">
<h4 data-number="1.2.11.1" class="anchored" data-anchor-id="errores-estándar-de-los-estimadores"><span class="header-section-number">1.2.11.1</span> Errores estándar de los estimadores</h4>
<p>De las propiedades obtenidas anteriormente para los estimadores de los parámetros del modelo, se puede proporcionar con ellos intervalos de confianza sobre tales parámetros. Concretamente, como <span class="math inline">\(\hat \beta_i\)</span> sigue una distribución normal <span class="math display">\[\hat \beta_i \pm t_{gl,\alpha/2} \cdot \hat s(\hat \beta_i)\]</span> donde <span class="math inline">\(gl\)</span> son los grados de libertad, <span class="math inline">\(\alpha\)</span> es el nivel de significación escogido de antemano y <span class="math inline">\(\hat s(\hat \beta_i)\)</span>, es el estimador de la desviación típica del estimador, también conocido como <strong>error estándar</strong> del estimador, que depende de la varianza residual.</p>
<p>El error estándar de la pendiente, <span class="math inline">\(\beta_1\)</span> es: <span class="math display">\[\hat s (\hat \beta_1)=\sqrt{\dfrac{\hat S_R^2}{nS_x^2}}=\sqrt{\frac{SC_{residual}/n-2}{SC_x}}\]</span> Y para la ordenada en el origen, <span class="math inline">\(\beta_0\)</span>: <span class="math display">\[\hat s (\hat \beta_0)=\sqrt{\frac{SC_{residual}}{n-2} \left( \dfrac{1}{n} + \dfrac{ \bar x^2}{SC_x}\right)}\]</span></p>
<p>Y podemos calcular intervalos de confianza tanto para la pendiente como para la ordenada en el origen.</p>
<p>Ahora bien, es más interesante poder calcular el error estándar y, con ello los intervalos de confianza, para las predicciones:</p>
<p><span class="math display">\[\hat s(\hat y) = \sqrt{\frac{SC_{residual}}{n-2} \left( \frac{1}{n}+\frac{(x_i-\bar{x})^2}{SC_x} \right)}\]</span></p>
<p><span class="math display">\[(\hat \beta_0 + \hat \beta_1\cdot x_i) \pm t_{n-2, \alpha/2} \cdot \hat s (\hat{y})\]</span></p>
<p>Con <code>R</code> será inmediato obtener intervalos de confianza para predicciones del modelo (tanto de la recta, como predicciones individuales). Algunos paquetes incluyen en los gráficos de regresión bandas de confianza para la respuesta media, <span class="math inline">\(\hat y\)</span>, para cada valor individual <span class="math inline">\(x_i\)</span>, habitualmente del 95%, que significa que tenemos una confianza de ese 95% en que la verdadera recta de regresión está en esa región marcada.</p>
</section>
</section>
<section id="sec-Leverage" class="level3" data-number="1.2.12">
<h3 data-number="1.2.12" class="anchored" data-anchor-id="sec-Leverage"><span class="header-section-number">1.2.12</span> Observaciones influyentes</h3>
<p>Se sabe que, cuanto más alejado de su media esté el valor <span class="math inline">\(x_i\)</span> observado más influencia tendrá sobre la pendiente de la recta de regresión. Sobre todo si no concuerda su pendiente respecto a la media, con la pendiente marcada por el resto de valores, y más si es un valor atípico.</p>
<p><strong>Leverage</strong><br>
El <em>leverage</em> (efecto palanca) es una medida necesaria para medir dicha influencia. En el caso de regresión lineal simple se puede calcular como: <span class="math display">\[h_i = \dfrac{1}{n} + \dfrac{(x_i - \bar x)^2 }{\sum_{j=1}^n(x_j - \bar x)^2 }  \]</span> Observando la fórmula se deduce que el <em>leverage</em> toma valores entre <span class="math inline">\(1/n\)</span> (cuando <span class="math inline">\(x_i=\bar x\)</span>) y <span class="math inline">\(1\)</span> (cuando <span class="math inline">\(x_i\)</span> esté muy alejado de <span class="math inline">\(\bar x\)</span>, véase <span class="citation" data-cites="Pena2002">Peña (<a href="#ref-Pena2002" role="doc-biblioref">2002</a>)</span> para detalles sobre esta acotación superior). A mayor <em>leverage</em> mayor influencia sobre la pendiente de la recta de regresión.</p>
<p><strong>Residuos estandarizados</strong><br>
Una observación con un valor de <em>leverage</em> próximo a <span class="math inline">\(1\)</span> puede hacer que la recta de regresión pase por tal observación (además de pasar por el centroide, <span class="math inline">\((\bar x, \bar y)\)</span>). Este hecho implica que en las observaciones con alto leverage, el residuo y su varianza son pequeños, mientras que en las observaciones cercanas a la media, el leverage es bajo y puede que su residuo y varianza sean más grandes. Por ello se suelen definir los <em>residuos estandarizados</em>: <span class="math display">\[r_i = \dfrac{u_i}{\hat S_R \sqrt{1-h_i}}\]</span> que siguen una distribución normal tipificada, si las hipótesis del modelo son ciertas. Generalmente, los programas de software estadístico calculan estos residuos estandarizados y dibujan algunos gráficos de residuos con ellos.</p>
<p><strong>Distancia de Cook</strong><br>
La distancia de Cook es la medida de influencia utilizada en la práctica. Se basa en medir el cambio en la recta de regresión al eliminar la observación <span class="math inline">\(i\)</span>. Viene dada por: <span class="math display">\[D_i = \dfrac{(\hat y_i - \hat y_{-i})^2}{2\hat S_R^2 h_i}\]</span> donde:</p>
<ul>
<li><span class="math inline">\(\hat y_i\)</span> es la estimación para la observación <span class="math inline">\(i\)</span>-ésima, basada en todos los datos,</li>
<li><span class="math inline">\(\hat y_{-i}\)</span> es la estimación para la observación <span class="math inline">\(i\)</span>-ésima, basada en todos los datos menos el <span class="math inline">\(i\)</span>-ésimo.</li>
</ul>
<p>Con esta medida, un punto es influyente si <span class="math inline">\(D_i&gt;1\)</span>. Los puntos con alto <em>leverage</em> pueden ser influyentes, pero no lo son siempre, por lo comentado al principio, si no concuerda su pendiente respecto a la pendiente marcada por el resto serán influyentes, pero si concuerda, no lo serán.</p>
<p>Un ejemplo aclarador podría ser el de dos variables claramente relacionadas. Pongamos por ejemplo, el PIB per cápita y la emisiones de CO2 de diferentes países. Se tendría una nube de puntos que indicase que a mayor PIB, mayores emisiones. Si el dato del PIB de uno de los países es muy grande (alejado de la media), y sus emisiones también son altas y acordes a la recta determinada por el resto de países, dicho país tendrá un alto <em>leverage</em>, pero su <em>distancia de Cook</em> no será mayor que 1. Por el contrario, si su valor de emisiones es muy distinto al que estimaría la recta determinada por el resto de países (sea dicho valor de emisiones mucho mayor o mucho menor), dicho país tendrá alto <em>leverage</em> y también alta <em>distancia de Cook</em>.</p>
</section>
<section id="sec-Transformaciones" class="level3" data-number="1.2.13">
<h3 data-number="1.2.13" class="anchored" data-anchor-id="sec-Transformaciones"><span class="header-section-number">1.2.13</span> Transformaciones</h3>
<p>Como se ha mencionado, puede ser útil transformar las variables para conseguir una relación lineal entre ellas, o conseguir homocedasticidad… Y así poder ajustarse con estas técnicas de modelos lineales. Por ejemplo si hay una relación exponencial entre las variables <span class="math inline">\(\mathbf{X}\)</span> e <span class="math inline">\(\mathbf{Y}\)</span>, se puede aplicar el logaritmo a <span class="math inline">\(\mathbf{Y}\)</span> linealizando así el modelo. O si la relación es potencial, considerar una potencia de la variable <span class="math inline">\(\mathbf{X}\)</span>: un modelo lineal de regresión no lineal. El tomar un modelo más complejo sólo tiene sentido si produce resultados significativos a la hora de explicar la relación. Ahora bien, hay que tener en cuenta que estas transformaciones pueden alterar la interpretación de los parámetros.</p>
<p>En la práctica, a la hora de transformar la variable respuesta, se acude a la familia de transformaciones Box-Cox, definida como: <span class="math display">\[
y^{(\lambda)} =
\begin{cases}
\frac{y^\lambda - 1}{\lambda}, &amp; \lambda \ne 0 \\
\ln y, &amp; \lambda = 0
\end{cases}
\]</span></p>
<p>Y cuyos casos particulares se esquematizan en la siguiente tabla:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th><span class="math inline">\(\lambda\)</span></th>
<th>Transformación</th>
<th>Nomenclatura</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(1\)</span></td>
<td><span class="math inline">\(y\)</span></td>
<td>Identidad</td>
</tr>
<tr class="even">
<td><span class="math inline">\(1/2\)</span></td>
<td><span class="math inline">\(\sqrt{y}\)</span></td>
<td>Raíz cuadrada</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(0\)</span></td>
<td><span class="math inline">\(\log y\)</span></td>
<td>Logaritmo natural</td>
</tr>
<tr class="even">
<td><span class="math inline">\(-1/2\)</span></td>
<td><span class="math inline">\(\frac{1}{\sqrt{y}}\)</span></td>
<td>Inversa de la raíz cuadrada</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(-1\)</span></td>
<td><span class="math inline">\(\frac{1}{y}\)</span></td>
<td>Inversa</td>
</tr>
</tbody>
</table>
<p>Estas transformaciones pueden conseguir linealidad siempre que la relación entre las variables sea monótona. Un pequeño detalle es tener en cuenta que transformaciones como la raíz cuadrada o el logaritmo no funcionan si la variable respuesta <span class="math inline">\(y_i\)</span> toma valores negativos, pero se puede subsanar considerando <span class="math inline">\(y_i+\delta\)</span> para evitarlo (aunque se pierde la interpretación directa de los resultados).</p>
<p>En ocasiones, no sólo es necesario la transformación de la variable respuesta, sino también de la explicativa. Y hay que tener en cuenta los efectos secundarios que pueden producir, por ejemplo, precaución con la interpretación de las estimaciones de los parámetros, sesgos en las predicciones, etc.</p>
</section>
</section>
<section id="sec-RLM" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="sec-RLM"><span class="header-section-number">1.3</span> Modelo lineal de regresión múltiple</h2>
<p>Cuando se dispone de más variables que podrían explicar la respuesta, entonces podemos plantear un modelo múltiples variables explicativas</p>
<p>Desde el punto de vista estadístico, surgen unas cuantas preguntas:</p>
<ul>
<li>¿Qué variables incluir en el modelo?</li>
<li>¿Están dichas variables explicativas correlacionadas entre ellas?</li>
<li>¿O interaccionan entre sí?</li>
<li>¿Hay curvatura en la respuesta?</li>
<li>…</li>
</ul>
<p>Por ello, la regresión múltiple tiene más retos que la simple. Entre otros:</p>
<ul>
<li>Es muy habitual tener demasiadas variables explicativas. Hay que seleccionar cuidadosamente cuáles incluir (se ve en <a href="Cap5-Seleccion.html" class="quarto-xref"><span>Capítulo 5</span></a>)</li>
<li>También el tener pocas observaciones, valores de la variable respuesta, frente al número elevado de parámetros del modelo… más si hay interacciones, si no se dispone de todas las combinaciones posibles de las variables explicativas, etc. Puede hacer que el modelo sea inestimable (<a href="#sec-Identificabilidad" class="quarto-xref"><span>Sección 1.3.4</span></a>).</li>
<li>Si hay correlación entre las variable explicativas, entonces aportan información redundante. Se puede detectar (<a href="#sec-Multicolinealidad" class="quarto-xref"><span>Sección 1.3.5</span></a>) y tratar de solucionar (<a href="Cap5-Seleccion.html" class="quarto-xref"><span>Capítulo 5</span></a>).</li>
<li>Si hay curvatura se debe acudir a modelos lineales, pero de regresión no lineal (<a href="#sec-ExtensionesRLM" class="quarto-xref"><span>Sección 1.5.3</span></a>).</li>
<li>La mayor parte de los estudios son observacionales, no experimentales (<a href="Cap2-DoE.html" class="quarto-xref"><span>Capítulo 2</span></a>).</li>
<li>…</li>
</ul>
<p>Recordemos, <em>…Todos los modelos son falsos…</em> Equivalentemente, el modelo perfecto y exacto no existe. Pero, algunos modelos son mejores que otros, y, en un modelo, la sencillez es un acierto (principio de parsimonia).</p>
<p>Tipos de modelos:</p>
<ul>
<li><strong>Saturado:</strong> Mismo número de observaciones que de parámetros. Ajuste perfecto. Grados de libertad 0.</li>
<li><strong>Maximal:</strong> Contiene p variables y sus interacciones. Muchos de estos términos son despreciables. Grados de libertad <span class="math inline">\(n-p-1\)</span>.</li>
<li><strong>Minimal y Adecuado</strong>: Contiene las variables e interacciones significativas. Grados de libertad <span class="math inline">\(n - p'-1\)</span>.</li>
<li><strong>Modelo Nulo</strong>: Un único parámetro, <span class="math inline">\(\beta_0 = \bar{y}\)</span>. Grados de libertad <span class="math inline">\(n-1\)</span>.</li>
</ul>
<section id="estimación-mc" class="level3" data-number="1.3.1">
<h3 data-number="1.3.1" class="anchored" data-anchor-id="estimación-mc"><span class="header-section-number">1.3.1</span> Estimación MC</h3>
<p>En <span class="citation" data-cites="Faraway">Faraway (<a href="#ref-Faraway" role="doc-biblioref">2004</a>)</span>, apartado 2.4, y en <span class="citation" data-cites="Pena2002">Peña (<a href="#ref-Pena2002" role="doc-biblioref">2002</a>)</span>, apartado 7.3.2, se puede ver la obtención del estimador MC para los parámetros del modelo de regresión lineal múltiple. Es la solución de las <strong>ecuaciones normales</strong>: <span class="math display">\[\mathbf{X}^\top \mathbf{X} \boldsymbol{\beta} = \mathbf{X}^\top \mathbf{Y} \quad \Longrightarrow  \quad \hat{\beta}=(\mathbf{X}^\top \mathbf{X})^{-1}\mathbf{X}^\top\mathbf{Y}\]</span> siempre que <span class="math inline">\(\mathbf{X}^\top \mathbf{X}\)</span> sea invertible.</p>
<p>Sale a relucir la matriz <span class="math inline">\(H=\mathbf{X}(\mathbf{X}^\top \mathbf{X})^{-1}\mathbf{X}^\top\)</span>, denominada matriz de proyecciones (hat-matrix, que es idempotente y simétrica), pues es la proyección ortogonal de <span class="math inline">\(\mathbf{Y}\)</span> en el espacio generado por las <span class="math inline">\(\mathbf{X}\)</span>. Con esta matriz, se pueden expresar:</p>
<ul>
<li>los valores predichos o estimados: <span class="math inline">\(\hat{\mathbf{Y}}=H\mathbf{Y}=\mathbf{X}\hat{\beta}\)</span></li>
<li>los residuos: <span class="math inline">\(\hat{\epsilon}=\mathbf{Y}-\mathbf{X}\hat{\beta}=(I-H)\mathbf{Y}\)</span></li>
<li>la suma de cuadrados residual (RSS por sus siglas en inglés): <span class="math inline">\(\hat{\epsilon}^\top\hat{\epsilon}=\mathbf{Y}^\top (I-H)\mathbf{Y}\)</span></li>
</ul>
<p>Se puede decir que el propósito del modelo es representar, de la mejor manera posible, la complejidad de la respuesta, dada en el espacio <span class="math inline">\(n\)</span>-dimensional, en un espacio más pequeño, el <span class="math inline">\(k\)</span>-dimensional de las variables. Si el modelo se ajusta bien, la estructura de los datos queda capturada en esas <span class="math inline">\(k\)</span> dimensiones, dejando la variación aleatoria en los residuos que pertenecen a un espacio de dimensión <span class="math inline">\(n-k\)</span>.</p>
</section>
<section id="sec-BondadAjusteMultiple" class="level3" data-number="1.3.2">
<h3 data-number="1.3.2" class="anchored" data-anchor-id="sec-BondadAjusteMultiple"><span class="header-section-number">1.3.2</span> Bondad de ajuste</h3>
<p>En el caso de regresión lineal <em>múltiple</em> la bondad de ajuste se puede medir con el coeficiente de determinación, <span class="math inline">\(R^2\)</span>, cuya fórmula es: <span class="math display">\[ R^2 = \dfrac{\text{Variabilidad explicada (VE)}}{\text{Variabilidad total (VT)}}=\dfrac{\sum (\hat y_i - \bar y)^2 }{\sum (y_i - \bar y)^2 }\]</span> A partir de <span class="math inline">\(R^2\)</span> se obtiene el coeficiente de correlación múltiple <span class="math inline">\(R\)</span>.</p>
<p>El <span class="math inline">\(R^2\)</span> ajustado/corregido es una corrección para suavizar el comportamiento de <span class="math inline">\(R^2\)</span> (que siempre aumenta al incluir en el modelo más variables explicativas). Consiste en considerar varianzas (medias de sumas de cuadrados, considerando sus respectivos grados de libertad, en lugar de sumas de cuadrados que se utilizan en <span class="math inline">\(R^2\)</span>): <span class="math display">\[ R^2_{\text{corregido}} = 1 - \dfrac{\text{Varianza residual}}{\text{Varianza de $y$}} = R^2 - (1 - R^2) \dfrac{k}{n+k-1}\]</span> Así, el <span class="math inline">\(R^2\)</span> corregido de una regresión múltiple siempre será menor que el <span class="math inline">\(R^2\)</span>, incluso podría tomar valores negativos.</p>
</section>
<section id="teorema-de-gauss-markov" class="level3" data-number="1.3.3">
<h3 data-number="1.3.3" class="anchored" data-anchor-id="teorema-de-gauss-markov"><span class="header-section-number">1.3.3</span> Teorema de Gauss-Markov</h3>
<p>Hay varias razones para usar el estimador MC de <span class="math inline">\(\beta\)</span>.</p>
<ul>
<li>es el resultado de una <strong>proyección ortogonal</strong> sobre el espacio del modelo (interpretación geométrica).</li>
<li>es también el <strong>estimador de máxima verosimilitud</strong> si los errores son independientes e idénticamente distribuidos siguiendo una normal.</li>
<li>es el <strong>mejor estimador lineal insesgado (BLUE)</strong> según el teorema de Gauss-Markov.</li>
</ul>
<blockquote class="blockquote">
<p><strong>Teorema de Gauss-Markov</strong><br>
Supongamos que <span class="math inline">\(E[\boldsymbol{\varepsilon}] = 0\)</span>, <span class="math inline">\(\text{Var}(\boldsymbol{\varepsilon}) = \sigma^2 \mathbf{I}\)</span> y que la parte estructural del modelo, <span class="math inline">\(E[\mathbf{y}] = \mathbf{X} \boldsymbol{\beta}\)</span>, es correcta.<br>
Sea <span class="math inline">\(\mathbf{c}^\top \boldsymbol{\beta}\)</span> una función estimable, entonces,<br>
dentro de la clase de todos los estimadores lineales insesgados de <span class="math inline">\(\mathbf{c}^\top \boldsymbol{\beta}\)</span>, el estimador de <strong>mínimos cuadrados</strong> tiene la <strong>varianza mínima</strong> y es <strong>único</strong>.</p>
</blockquote>
<blockquote class="blockquote">
<p>Una función <span class="math inline">\(\mathbf{c}^\top \boldsymbol{\beta}\)</span> es <em>estimable</em>, si, y solo si, existe una combinación lineal <span class="math inline">\(\mathbf{a}^\top \mathbf{y}\)</span> tal que <span class="math inline">\(E[\mathbf{a}^\top \mathbf{y}] = \mathbf{c}^\top \boldsymbol{\beta}\)</span>.</p>
</blockquote>
<p>La demostración puede encontrarse en <span class="citation" data-cites="Faraway">Faraway (<a href="#ref-Faraway" role="doc-biblioref">2004</a>)</span>, apartado 2.6.</p>
<p>Las funciones estimables incluyen predicciones de observaciones futuras, lo que explica por qué vale la pena considerarlas. Si la matriz <span class="math inline">\(\mathbf{X}\)</span> tiene rango completo, entonces todas las combinaciones lineales son estimables.</p>
<p><strong>Consideraciones adicionales</strong><br>
El teorema de Gauss-Markov recomienda usar mínimos cuadrados, salvo que haya una buena razón para no hacerlo. Como cuando los errores estén correlados y la varianza no sea constante, incumpliendo así los supuestos del teorema. En tal caso se deben usar mínimos cuadrados generalizados.<br>
Si los errores son no normales pero se comportan bien, típicamente con colas pesadas, puede que estimadores robustos, generalmente no lineales, funcionen mejor. O cuando se da multicolinealidad, se pueden preferir estimadores sesgados como la regresión ridge (véase <a href="Cap5-Seleccion.html#sec-RegRidge" class="quarto-xref"><span>Sección 5.4</span></a>)</p>
</section>
<section id="sec-Identificabilidad" class="level3" data-number="1.3.4">
<h3 data-number="1.3.4" class="anchored" data-anchor-id="sec-Identificabilidad"><span class="header-section-number">1.3.4</span> Identificabilidad</h3>
<p>La identificabilidad es un concepto clave en modelos estadísticos, especialmente en regresión. Un modelo es <strong>identificable</strong> si los parámetros del modelo pueden ser estimados de manera única a partir de los datos observados. En otras palabras, para cada conjunto de datos, hay una única solución para la estimación de los parámetros del modelo. Un modelo es <em>no identificable</em> si hay múltiples conjuntos de parámetros que pueden generar los mismos datos observados. Esto puede ocurrir por varias razones, como la presencia de variables redundantes o la falta de información suficiente en los datos para distinguir entre diferentes configuraciones de parámetros.</p>
<p>Si <span class="math inline">\(\mathbf{X}^\top \mathbf{X}\)</span> no tiene rango completo, es decir, cuando sus columnas son <em>linealmente dependientes</em>, es <em>singular</em> y no puede invertirse, entonces habrá infinitas soluciones para las ecuaciones normales y el modelo será, al menos en parte, no identificable.</p>
<p>Los paquetes estadísticos manejan la no identificabilidad de distintas formas. Algunos pueden devolver mensajes de error, y otros pueden ajustar el modelo porque los errores de redondeo eliminan la no identificabilidad exacta. En otros casos, se aplican restricciones, pero estas pueden ser diferentes de las que uno espera. Por defecto, <code>R</code> ajusta el modelo identificable más grande, eliminando variables en orden inverso al que aparecen en la fórmula del modelo.</p>
</section>
<section id="sec-Multicolinealidad" class="level3" data-number="1.3.5">
<h3 data-number="1.3.5" class="anchored" data-anchor-id="sec-Multicolinealidad"><span class="header-section-number">1.3.5</span> Multicolinealidad</h3>
<p>En la regresión múltiple, hay que tener claro que la correlación se desea entre cada variable explicativa y la respuesta, y no entre ellas. De haber una alta correlación entre variables explicativas se presenta el problema denominado <em>multicolinealidad</em>. Aquellas variables que presentan multicolinealidad producen una aumento de la varianza del estimador, y, con ello, una peor precisión para detectar significatividad. Para resolverlo se puede acudir a la <em>selección de variables</em> (<a href="Cap5-Seleccion.html" class="quarto-xref"><span>Capítulo 5</span></a>), teniendo en cuenta medidas como el <em>factor de inflación de la varianza</em> (VIF) que vemos en este apartado. Ahora bien, conviene recordar que <em>correlación no implica causalidad</em> (ejemplos: delitos vs policías, limones vs accidentes,…).</p>
<p>Existen distintas vías para detectar el grado de multicolinealidad existente. Por ejemplo, la matriz de correlaciones lineales y su determinante, el factor de inflación de la varianza, el número de condición, etc.</p>
<p>Nos centramos en el <strong>factor de inflación de la varianza (VIF)</strong>. Su cálculo para cada parámetro <span class="math inline">\(\beta_i\)</span> se puede obtener al realizar una regresión (auxiliar) tomando como variable respuesta la variable asociada a dicho parámetro, <span class="math inline">\(\mathbf{X}_i\)</span>, y como predictores el resto de variables explicativas: <span class="math display">\[\mathbf{X}_i = \alpha_0 + \alpha_1 \mathbf{X}_1 + \ldots + \alpha_{i-1}\mathbf{X}_{i-1} + \alpha_{i+1}\mathbf{X}_{i+1} + \ldots + \alpha_k \mathbf{X}_k.\]</span> Si el coeficiente de determinación de esta regresión auxiliar, <span class="math inline">\(R_i^2\)</span>, es alto, dicha variable <span class="math inline">\(\mathbf{X}_i\)</span> tiene una alta relación lineal con el resto de variables, tiene <em>multicolinealidad</em>. El factor de inflación de la varianza se define como: <span class="math display">\[\text{VIF}(\beta_i) = \dfrac{1}{1 - R_i^2}\]</span> El VIF tomará valores entre 1 e <span class="math inline">\(\infty\)</span>, indicando los valores cercanos a 1 ausencia de <em>multicolinealidad</em>. Si, por ejemplo, <span class="math inline">\(R_i^2 = 0.9\)</span> (o <span class="math inline">\(0.8\)</span>) se tendría VIF<span class="math inline">\(=10\)</span> (o 5) valor que se toma en la práctica para alertar de alta multicolinealidad.</p>
<blockquote class="blockquote">
<p>El lector interesado puede obtener más información en: <a href="https://rnoremlas.quarto.pub/un_rincon_para_r/posts/17_multicolinealidad/">Multicolinealidad. Detección</a>, del interesante blog “Un rincón para R” de Román Salmerón (UGR).</p>
</blockquote>
</section>
</section>
<section id="sec-LM-Airquality" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="sec-LM-Airquality"><span class="header-section-number">1.4</span> Caso práctico: <code>airquality</code></h2>
<p>El primero de los casos prácticos de modelización lineal que se va a tratar en profundidad se basa en los datos <code>airquality</code> que contienen 153 medidas (de 6 variables) de calidad del aire en Nueva York. Entre otros, se estudia en <span class="citation" data-cites="CDRlm">Casero-Alonso y Durbán (<a href="#ref-CDRlm" role="doc-biblioref">2024</a>)</span>, concretamente en: <a href="https://cdr-book.github.io/cap-lm.html#Casos" class="uri">https://cdr-book.github.io/cap-lm.html#Casos</a>. Aquí se presentan ejemplos ligeramente distintos y con algo más de detalle.</p>
<section id="exploración-de-los-datos" class="level3" data-number="1.4.1">
<h3 data-number="1.4.1" class="anchored" data-anchor-id="exploración-de-los-datos"><span class="header-section-number">1.4.1</span> Exploración de los datos</h3>
<p>Antes de comenzar el proceso de modelización lineal, es muy recomendable explorar los datos. El conjunto de datos <code>airquality</code> está disponible en la distribución base de R:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>?airquality <span class="co">#Para obtener más información sobre las variables, unidades, etc. </span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Primeras filas del data frame</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(airquality)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  Ozone Solar.R Wind Temp Month Day
1    41     190  7.4   67     5   1
2    36     118  8.0   72     5   2
3    12     149 12.6   74     5   3
4    18     313 11.5   62     5   4
5    NA      NA 14.3   56     5   5
6    28      NA 14.9   66     5   6</code></pre>
</div>
</div>
<p>Como se observa hay varios valores perdidos (<code>NA</code>: <em>Not Available</em>) entre los datos, lo que puede afectar a los resultados de la regresión. Su impacto debe estudiarse, pero sobrepasa el nivel de este curso.</p>
<p>Además, al observar detenidamente los valores de la variable <code>Day</code> se puede inferir que los datos son temporales, lo que requiere un análisis específico (de <em>Series Temporales</em>, que también sobrepasa el alcance de este curso). El tener datos temporales hace que se incumpla, de partida, desde el plano teórico/conceptual, el supuesto de independencia (<a href="#sec-Independencia" class="quarto-xref"><span>Sección 1.2.9.4</span></a>).</p>
<p>Aun con esta situación (valores perdidos, datos temporalmente dependientes) se analizan aquí diversos modelos lineales. Eso sí, no tiene sentido intentar explicar la influencia lineal de la variable <code>Day</code> en el resto de variables, por ejemplo, por el hecho de que los días <span class="math inline">\(1\)</span>, <span class="math inline">\(2\)</span>, etc. de meses distintos no son homogéneos, etc.</p>
<p>Procedemos a obtener resúmenes numéricos y gráficos:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Resúmenes numéricos de las variables</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(airquality)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     Ozone           Solar.R           Wind             Temp      
 Min.   :  1.00   Min.   :  7.0   Min.   : 1.700   Min.   :56.00  
 1st Qu.: 18.00   1st Qu.:115.8   1st Qu.: 7.400   1st Qu.:72.00  
 Median : 31.50   Median :205.0   Median : 9.700   Median :79.00  
 Mean   : 42.13   Mean   :185.9   Mean   : 9.958   Mean   :77.88  
 3rd Qu.: 63.25   3rd Qu.:258.8   3rd Qu.:11.500   3rd Qu.:85.00  
 Max.   :168.00   Max.   :334.0   Max.   :20.700   Max.   :97.00  
 NA's   :37       NA's   :7                                       
     Month            Day      
 Min.   :5.000   Min.   : 1.0  
 1st Qu.:6.000   1st Qu.: 8.0  
 Median :7.000   Median :16.0  
 Mean   :6.993   Mean   :15.8  
 3rd Qu.:8.000   3rd Qu.:23.0  
 Max.   :9.000   Max.   :31.0  
                               </code></pre>
</div>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Estructura (formato) del data frame</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(airquality)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>'data.frame':   153 obs. of  6 variables:
 $ Ozone  : int  41 36 12 18 NA 28 23 19 8 NA ...
 $ Solar.R: int  190 118 149 313 NA NA 299 99 19 194 ...
 $ Wind   : num  7.4 8 12.6 11.5 14.3 14.9 8.6 13.8 20.1 8.6 ...
 $ Temp   : int  67 72 74 62 56 66 65 59 61 69 ...
 $ Month  : int  5 5 5 5 5 5 5 5 5 5 ...
 $ Day    : int  1 2 3 4 5 6 7 8 9 10 ...</code></pre>
</div>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Resumen gráfico de relaciones pareadas</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(airquality, <span class="at">upper.panel =</span> panel.smooth)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Cap1-LM_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Del resumen numérico se obtiene que hay 2 variables <code>Ozone</code> y <code>Solar.R</code> que contienen <code>NA</code>s, principalmente la primera con 37 valores no disponibles. Estos resúmenes, junto con la visualización de la estructura (y la consulta de las unidades en las que están medidas) permiten determinar que las variables <code>Ozone</code>, <code>Solar.R</code>, <code>Wind</code> y <code>Temp</code> se pueden considerar cuantitativas continuas (obsérvense sus rangos) a los efectos de modelización lineal, aunque sólo <code>Wind</code> esté definida como <code>num</code> (y el resto como <code>int</code>). Sobre <code>Temp</code>, viendo el rango de sus valores (de 56 a 97), no parece que estén en ºC. ¿Y cómo considerar a la variable <code>Month</code>? El tratamiento más adecuado es como variable cualitativa, dado que, aunque vemos valores numéricos, de 5 a 9, no puede interpretarse como una variable continua en la que tenga sentido incrementar 1 unidad. Además, otorgarle valores 5 a 9 es un convenio para tratarlas por ordenador de una manera más cómoda, pero realmente sus valores son <code>mayo</code>, <code>junio</code>… Queda así más claro que no tiene sentido aumentar 1 unidad, por ejemplo, cuando estamos en el mes 12.</p>
<p>De los diagramas de dispersión, al incluir el argumento <code>panel.smooth</code> se pueden observar líneas de tendencias suavizadas de los datos. Se aprecia que casi ninguna de las relaciones entre las variables numéricas es lineal, sólo lo parece <code>Wind</code> frente a <code>Temp</code>. Los gráficos que involucran a la variable <code>Month</code> se aprecian distintos al resto, por los pocos valores de dicha variable, mientras que los que involucran a <code>Day</code> no reflejan lo mismo.</p>
<blockquote class="blockquote">
<p>Alternativas: Existen distintas funciones/paquetes más o menos sofisticados que realizan este <em>análisis exploratorio</em> de distintas maneras. El lector interesado puede explorar:<br>
- El paquete <code>skimr</code> y su función <code>skim()</code>.<br>
- El paquete <code>summarytools</code> y su función <code>dfSummary()</code>.<br>
- …</p>
</blockquote>
<blockquote class="blockquote">
<p>Por ejemplo, con las siguientes funciones se pueden obtener gráficos complementarios al gráfico obtenido anteriormente con <code>pairs()</code>.</p>
</blockquote>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Es necesario tener los paquetes instalados previamente</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(corrplot) </span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="fu">corrplot</span>(<span class="fu">cor</span>(airquality, <span class="at">use =</span> <span class="st">"pairwise"</span>))</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(GGally)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggpairs</span>(airquality)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="co">#Para que aparezca los diagramas de dispersión "arriba"</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="fu">ggpairs</span>(airquality,</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>         <span class="at">upper =</span> <span class="fu">list</span>(<span class="at">continuous =</span> <span class="fu">wrap</span>(<span class="st">"points"</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>)),  </span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>         <span class="at">lower =</span> <span class="fu">list</span>(<span class="at">continuous =</span> <span class="fu">wrap</span>(<span class="st">"cor"</span>, <span class="at">size =</span> <span class="dv">4</span>)),  </span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>         <span class="at">diag =</span> <span class="fu">list</span>(<span class="at">continuous =</span> <span class="fu">wrap</span>(<span class="st">"densityDiag"</span>)))  </span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="lm-simple" class="level3" data-number="1.4.2">
<h3 data-number="1.4.2" class="anchored" data-anchor-id="lm-simple"><span class="header-section-number">1.4.2</span> lm() simple</h3>
<p>Para ilustrar la teoría de las secciones anteriores se va a realizar aquí una regresión lineal simple. La función <code>lm()</code> de <code>R</code> proporciona, a partir de los datos disponibles, la estimación de los parámetros del modelo que se especifique. También se pueden obtener, aplicando distintas funciones, la significación de dichas estimaciones, sus intervalos de confianza, predicciones, etc. Así como los gráficos de diagnóstico.</p>
<p><strong>Modelización</strong><br>
A diferencia del libro CDR, se considera para empezar un modelo de regresión simple. De entre los posibles modelos nos decantamos por intentar explicar la concentración de Ozono en función de la radiación solar: <span class="math display">\[Ozone = \beta_0 + \beta_1 Solar.R + \epsilon\]</span></p>
<blockquote class="blockquote">
<p>El lector tiene aquí una buena tarea conceptual, la de ejercitarse en plantear modelizaciones lineales, que ¡tengan sentido práctico!<br>
¿Tiene sentido explicar/predecir <code>Ozone</code> en función de los valores de <code>Solar.R</code> observados? ¿Y al revés? ¿O explicar/predecir <code>Day</code> en función de <code>Ozone</code>? …</p>
</blockquote>
<p>En <code>R</code> definiríamos así el modelo anterior:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>modelo <span class="ot">&lt;-</span> Ozone <span class="sc">~</span> Solar.R</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<blockquote class="blockquote">
<p>La sintaxis básica (regresión simple) es <code>respuesta ~ explicativa</code>.<br>
La extensión a regresión múltiple es directa: <code>resp ~ explica1 + explica2</code> indicaría un modelo con predictores <code>explica1</code> y <code>explica2</code>, y así sucesivamente.<br>
En el ejemplo de regresión múltiple se indican algunos “trucos/atajos” para definir modelos.</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>Pregunta</strong><br>
¿Cómo obtener la regresión de proporcionalidad directa con <code>R</code>?</p>
</blockquote>
<p><strong>Estimación</strong><br>
En <code>R</code> pueden obtenerse de varias maneras utilizando la función <code>lm()</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Opción 1: aprovechando la definición anterior del modelo</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="co">#lm(modelo, data = airquality) </span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Opción 2: directa -&gt; lectura más clara</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(Ozone <span class="sc">~</span> Solar.R, </span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>   <span class="at">data =</span> airquality)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = Ozone ~ Solar.R, data = airquality)

Coefficients:
(Intercept)      Solar.R  
    18.5987       0.1272  </code></pre>
</div>
</div>
<p>Aquí se pueden ver las estimaciones para los dos parámetros obtenidas a partir de los datos (omitiendo las observaciones con valores <code>NA</code>).</p>
<blockquote class="blockquote">
<p>La función lm() aplicada a un modelo simple <code>y ~ x</code> (o múltiple) requiere que los datos de las variables <code>y</code> y <code>x</code> estén en el <code>Environment</code>, o se especifique en <code>data</code> el conjunto de datos en el que están las dos variables.</p>
</blockquote>
<p><strong>Diagrama de dispersión y recta estimada</strong></p>
<p>Dado que se está analizando la relación entre dos variables, esta se puede visualizar fácilmente en un diagrama de dispersión, al que se puede añadir la recta estimada a partir de los datos.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">pty =</span> <span class="st">"s"</span>) <span class="do">## "p"lot "ty"pe "s"quare (recomendado para gráficos de dispersión)</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(airquality<span class="sc">$</span>Solar.R, airquality<span class="sc">$</span>Ozone)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a=</span><span class="fl">18.5987</span>, <span class="at">b=</span><span class="fl">0.1272</span>, <span class="at">col =</span> <span class="st">"red"</span>) <span class="do">## a = intercept, b = slope</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Cap1-LM_files/figure-html/unnamed-chunk-11-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>En problemas de regresión múltiple con dos variables explicativas se puede obtener un diagrama de dispersión en 3 dimensiones y añadirle el plano de regresión, pero suele ser compleja su visualización. Con más variables es imposible obtener tales visualizaciones, diagramas de dispersión en <span class="math inline">\(k\)</span> dimensiones e hiperplanos de regresión, lo que conduce a abordar el problema de regresión lineal múltiple mediante un proceso de abstracción.</p>
<p><strong>Análisis de residuos</strong><br>
Valoremos la adecuación del modelo examinando los residuos. Primero guardamos el ajuste/estimación basado en los datos en un objeto, que denominamos <code>rls</code>, para su uso posterior:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>rls <span class="ot">&lt;-</span> <span class="fu">lm</span>(Ozone <span class="sc">~</span> Solar.R, <span class="at">data =</span> airquality)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>), <span class="co">#presenta los gráficos en formato 2x2</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">pty =</span> <span class="st">"s"</span>,</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">mex =</span> <span class="fl">0.66</span>,</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">cex =</span> <span class="fl">0.75</span>)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(rls)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Cap1-LM_files/figure-html/unnamed-chunk-12-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<ul>
<li><p>El primero de los 4 gráficos de diagnóstico (Residuals vs Fitted) refleja heterocedasticidad (varianza no constante, forma de embudo), tal y como ya se podía apreciar en el diagrama de dispersión de <code>Solar.R</code> frente a <code>Ozone</code> que se obtuvo anteriormente. En este gráfico de aquí, conforme aumenta el valor de los valores estimados (fitted), la dispersión de los residuos se hace más grande, salvo en la parte final. Este gráfico también sirve para comprobar si se cumple (o no) la linealidad, aquí, la linea suavizada incluida es bastante plana, salvo, de nuevo, en la parte final.</p></li>
<li><p>El gráfico que mejor refleja esa heterocedasticidad es el tercero (Scale-Location), donde la línea roja de tendencia dista de la horizontalidad (que reflejaría homocedasticidad) teniendo una pendiente positiva (ligera, pero apreciable).</p></li>
<li><p>Respecto a la normalidad, a la vista del segundo gráfico (Q-Q Residuals), se observa una clara desviación de la linea recta punteada (que marcaría el ajuste perfecto a la distribución normal), sobre todo en la parte superior derecha. Para reforzar la impresión de este gráfico se puede acudir a otra visualización y a un contraste. Lo más apropiado es un histograma y el contraste de Shapiro-Wilk:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(<span class="fu">residuals</span>(rls))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Cap1-LM_files/figure-html/unnamed-chunk-13-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">shapiro.test</span>(<span class="fu">residuals</span>(rls))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
  Shapiro-Wilk normality test

data:  residuals(rls)
W = 0.91418, p-value = 2.516e-06</code></pre>
</div>
</div>
<p>El histograma refleja una clara asimetría, que dista de la simetría de la distribución normal. Y el p-valor del contraste lleva claramente a rechazar la normalidad.</p></li>
<li><p>El último de los 4 gráficos de residuos (Residuals vs Leverage) señala las observaciones 117 y 62 como los valores con más influencia en los resultados de la regresión. Pero en este último gráfico no presentan un valor grande de la distancia de Cook, que sirve para medir esa influencia. De hecho, no aparecen en el gráfico ni las lineas discontinuas que marcan los límites para considerar un valor grande de la distancia, <span class="math inline">\(D_i &gt; 0.5\)</span> y <span class="math inline">\(D_i&gt;1\)</span>, y por lo tanto una posible observación influyente.</p>
<blockquote class="blockquote">
<p>Los valores de <em>leverage</em> se pueden obtener usando la función <code>hatvalues()</code>.</p>
</blockquote>
<blockquote class="blockquote">
<p>la función <code>plot()</code> aplicada a un objeto de tipo <code>lm</code> en realidad calcula 6 gráficos, que se pueden obtener así:</p>
</blockquote>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(rls, <span class="at">which =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></li>
</ul>
<p>En <strong>resumen</strong>, es claro que hay dos observaciones que pueden influir en los resultados de la regresión, pero también es claro que los problemas observados (heterocedasticidad, falta de normalidad…) no provienen sólo de esos dos datos.</p>
<blockquote class="blockquote">
<p><strong>Pregunta</strong><br>
Repita el análisis manteniendo <code>Ozone</code> como variable respuesta/dependiente, cambiando la variable explicativa <code>Solar.R</code> por <code>Wind</code> o <code>Temp</code>. ¿Aprecia algún cambio?</p>
</blockquote>
<blockquote class="blockquote">
<p>Alternativas: Existen distintas funciones/paquetes más o menos sofisticados que realizan este <em>análisis de residuos</em> de distintas maneras. El lector interesado puede explorar:<br>
- El paquete <code>ggfortify</code> y su función <code>autoplot()</code>.<br>
- El paquete <code>performance</code> y su función <code>check_model()</code>.<br>
- …</p>
</blockquote>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Es necesario tener los paquetes instalados previamente</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"ggfortify"</span>)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(rls) <span class="sc">+</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(performance) </span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(see)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="fu">check_model</span>(rls)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Interpretación e Inferencia</strong><br>
Supongamos que fuese todo correcto. El siguiente paso sería el de averiguar la significación de los parámetros, interpretarlos y obtener alguna predicción de interés. Aplicamos la función <code>summary()</code> a nuestro objeto <code>rls</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(rls)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = Ozone ~ Solar.R, data = airquality)

Residuals:
    Min      1Q  Median      3Q     Max 
-48.292 -21.361  -8.864  16.373 119.136 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 18.59873    6.74790   2.756 0.006856 ** 
Solar.R      0.12717    0.03278   3.880 0.000179 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 31.33 on 109 degrees of freedom
  (42 observations deleted due to missingness)
Multiple R-squared:  0.1213,    Adjusted R-squared:  0.1133 
F-statistic: 15.05 on 1 and 109 DF,  p-value: 0.0001793</code></pre>
</div>
</div>
<p>En esta salida obtenemos, además de las estimaciones, <span class="math inline">\(\hat{\beta}_0\)</span> y <span class="math inline">\(\hat{\beta}_1\)</span> (columna <code>Estimate</code>), mucha información para su interpretación. En la columna <code>Pr(&gt;|t|)</code> se pueden ver los p-valores de cada parámetro. El del parámetro asociado a la variable <code>Solar.R</code> es muy pequeño, pudiéndose concluir, en caso de que el modelo fuese válido, que la variable <code>Solar.R</code> influye significativamente en la variable <code>Ozone</code>. De la misma manera, el parámetro <span class="math inline">\(\beta_0\)</span> (<code>(Intercept)</code>, intersección/ordenada en el origen) es significativo, lo que indica que el modelo no pasa por el origen de coordenadas. Los p-valores obtenidos provienen, de la estimación del estadístico <span class="math inline">\(t\)</span> que se encuentra en la columna <code>t value</code>, que a su vez se basa en la mencionada estimación de cada parámetro (columna <code>Estimate</code>) y el error estándar (columna <code>Std. Error</code>) (véase <a href="#sec-CH" class="quarto-xref"><span>Sección 1.2.6</span></a>). A partir de estos dos valores y la distribución <span class="math inline">\(t\)</span> correspondiente, se pueden obtener los intervalos de confianza “a mano” (paso a paso con <code>R</code>, aplicando las fórmulas de la <a href="#sec-Prediccion" class="quarto-xref"><span>Sección 1.2.11</span></a>), pero se dispone de la función <code>confint()</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(rls)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                 2.5 %     97.5 %
(Intercept) 5.22460110 31.9728544
Solar.R     0.06220373  0.1921268</code></pre>
</div>
</div>
<p>Si el modelo fuese válido se pasaría a la interpretación de estos parámetros… Primero, el signo de <span class="math inline">\(\hat{\beta}_1\)</span>, al ser positivo, indica que conforme aumenta <code>Solar.R</code> también aumenta <code>Ozone</code>. Esta conclusión es clara aunque el modelo no sea válido. Ahora bien, no sólo se obtiene esa relación positiva, sino la magnitud de dicha relación. Así, el cambio de 1 unidad en <code>Solar.R</code> implicaría un cambio medio de aproximadamente 0.1272 unidades en <code>Ozone</code>, con un valor medio de 18.5987 unidades de <code>Ozone</code> en ausencia de radiación solar (¡Ojo! Con los datos disponibles, el mínimo valor de <code>Solar.R</code> es 7, según la tabla del resumen numérico, por lo que estamos hablando de una <em>extrapolación</em> que necesitaría del conocimiento de un experto en la materia para dilucidar su apropiada y/o oportuna interpretación).</p>
<p><strong>Bondad de ajuste</strong><br>
En la salida anterior de la función <code>summary()</code> también se pueden observar resultados que ayudan a proporcionar la bondad de ajuste de la regresión simple planteada. El valor que resume la bondad de ajuste es el <code>Multiple R-squared</code>, aunque, como se ha mencionado en <a href="#sec-BondadAjusteMultiple" class="quarto-xref"><span>Sección 1.3.2</span></a>, para comparar entre modelos conviene hacerlo con el <code>Adjusted R-squared</code> que arroja un valor de</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>rls.summ <span class="ot">&lt;-</span> <span class="fu">summary</span>(rls)  <span class="co">#guardamos el objeto generado con summary()</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="co">#con names() listamos distintos componentes generados con summary() </span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(rls.summ)           <span class="co">#también se puede consultar con ?summary.lm </span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] "call"          "terms"         "residuals"     "coefficients" 
 [5] "aliased"       "sigma"         "df"            "r.squared"    
 [9] "adj.r.squared" "fstatistic"    "cov.unscaled"  "na.action"    </code></pre>
</div>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(rls)<span class="sc">$</span>adj.r.squared</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.1132809</code></pre>
</div>
</div>
<p>Este 11.3% se puede considerar “pobre”. La variable <code>Solar.R</code> explica “pobremente” el <code>Ozone</code>. No obstante, el p-valor global del modelo que se muestra en la última linea de la salida de <code>summary()</code> es significativo, indicando que la recta de regresión es significativa, esto es, que es mejor que proporcionar sólo la media de <code>Ozone</code> para cualquier valor de <code>Solar.R</code> que sería el modelo básico.</p>
<blockquote class="blockquote">
<p><strong>Pregunta</strong><br>
¿Sabe decir porqué el p-valor de la recta de regresión coincide con el del parámetro asociado a <code>Solar.R</code>?</p>
</blockquote>
<p>También se puede observar el valor del <code>Residual standard error</code> y sus grados de libertad, <span class="math inline">\(n-2\)</span> (véase <a href="#sec-HatVarianza" class="quarto-xref"><span>Sección 1.2.4</span></a>). Aunque, en este caso, hay que tener en cuenta el mensaje que aparece en la salida: <code>42 observations deleted due to missingness</code>, que indica que no se han considerado aquellas observaciones en las que cualquier variable tiene un <code>NA</code>. Así, los grados de libertad quedan en <span class="math inline">\(109\)</span>.</p>
<p><strong>Predicción</strong><br>
A pesar de que el modelo no es idóneo para explicar el fenómeno, puede que la regresión lineal sirva para el propósito de predecir valores. Pasamos a ilustrar como se obtendrían con <code>R</code> predicciones a partir de la recta estimada:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(rls, <span class="fu">data.frame</span>(<span class="at">Solar.R =</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">100</span>, <span class="dv">300</span>)),</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>        <span class="at">interval =</span> <span class="st">"confidence"</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       fit       lwr      upr
1 19.87038  7.076164 32.66460
2 31.31525 23.247138 39.38337
3 56.74831 47.222078 66.27454</code></pre>
</div>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(rls, <span class="fu">data.frame</span>(<span class="at">Solar.R =</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">100</span>, <span class="dv">300</span>)),</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>        <span class="at">interval =</span> <span class="st">"prediction"</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       fit        lwr       upr
1 19.87038 -43.537910  83.27867
2 31.31525 -31.310729  93.94124
3 56.74831  -6.082164 119.57878</code></pre>
</div>
</div>
<p>Con el argumento <code>interval = "confidence"</code> obtenemos <em>intervalos de confianza</em> (para valores medios), con <code>interval = "prediction"</code> obtenemos <em>intervalos de predicción</em> (para valores individuales) para la predicción de <code>Ozone</code> dados valores de <code>Solar.R</code>. Concretamente para 3 valores: 10, 100 y 300, todos ellos en el rango de valores observados de la variable. La estimación media (<code>fit</code>) coincide en ambos casos, diferenciándose en la <em>amplitud</em> de los intervalos, mucho mayores para los intervalos de predicción, dado que, para el mismo valor de <code>Solar.R</code>, una observación individual puede alejarse mucho más de la media, que una media de varias observaciones .</p>
</section>
<section id="lm-múltiple" class="level3" data-number="1.4.3">
<h3 data-number="1.4.3" class="anchored" data-anchor-id="lm-múltiple"><span class="header-section-number">1.4.3</span> lm() múltiple</h3>
<p><strong>Modelización y estimación</strong><br>
Se aborda aquí una regresión lineal múltiple ligeramente distinta a la del libro CDR. Directamente en formato de <code>R</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>rlm <span class="ot">&lt;-</span> <span class="fu">lm</span>(Ozone <span class="sc">~</span> Solar.R <span class="sc">+</span> Wind <span class="sc">+</span> Temp <span class="sc">+</span> Month, <span class="at">data =</span> airquality) </span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="do">## Equivalentemente</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="co">#rlm &lt;- lm(Ozone ~ . - Day, data = airquality)</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<blockquote class="blockquote">
<p><strong>Trucos/atajos</strong>: Para no escribir todas las variables, se hace uso de <code>.</code>: <code>lm(y ~ ., data)</code> indica una regresión con <code>y</code> como variable respuesta, y el resto de variables de <code>data</code> como predictores lineales.<br>
Además, se ha usado <code>-</code> para quitar la variable indicada.</p>
</blockquote>
<p><strong>Análisis de residuos</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>), <span class="co">#presenta los gráficos en formato 2x2</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">pty =</span> <span class="st">"s"</span>,</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">mex =</span> <span class="fl">0.66</span>,</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">cex =</span> <span class="fl">0.75</span>)</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(rlm)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Cap1-LM_files/figure-html/unnamed-chunk-21-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<blockquote class="blockquote">
<p><strong>Pregunta</strong><br>
¿Se ha mejorado respecto a la regresión simple?</p>
</blockquote>
<p>Nótese que ahora, en el 4º gráfico (Residuals vs Leverage) sí que aparece la línea punteada del valor 0.5 de la distancia de Cook, que no llega a alcanzar ninguno de los datos.</p>
<p><strong>Interpretación</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(rlm)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = Ozone ~ Solar.R + Wind + Temp + Month, data = airquality)

Residuals:
    Min      1Q  Median      3Q     Max 
-35.870 -13.968  -2.671   9.553  97.918 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -58.05384   22.97114  -2.527   0.0130 *  
Solar.R       0.04960    0.02346   2.114   0.0368 *  
Wind         -3.31651    0.64579  -5.136 1.29e-06 ***
Temp          1.87087    0.27363   6.837 5.34e-10 ***
Month        -2.99163    1.51592  -1.973   0.0510 .  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 20.9 on 106 degrees of freedom
  (42 observations deleted due to missingness)
Multiple R-squared:  0.6199,    Adjusted R-squared:  0.6055 
F-statistic: 43.21 on 4 and 106 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>Si del análisis de residuos queda validado el modelo, se pueden interpretar los parámetros del modelo estimado, ¿qué explican/aportan?, o ¿cómo influyen?, cada uno a la respuesta (siempre en términos medios). De la salida anterior se desprende que, de las 4 variables consideradas, la más significativa es <code>Temp</code>, seguida de <code>Wind</code> (ambas con 3 asteriscos), y también es significativa <code>Solar.R</code>, pero a otro nivel (sólo un asterisco, por un valor inferior al 5% pero superior al 1%, cuando en la regresión simple tenía un p-valor más pequeño/significativo, 2 asteriscos). Por último, <code>Month</code> es significativa pero a un nivel del 10% de significación. También el término independiente es significativo.</p>
<p>Sobre la interpretación de los parámetros, se debe tener en cuenta las unidades en las que están recogidas cada una de las variables. Como se ha mencionado, cualquier cambio de escala influirá en dichas estimaciones, y generalmente en sus <code>Std. Error</code> (salvo <em>traslaciones</em> de las variables).</p>
<p>Además, la interpretación de las estimaciones (magnitud) como cambios en la variable respuesta tiene ahora un cambio sustancial. El cambio en la variable respuesta de 1 unidad de una de las variables explicativas está condicionado a que el resto de variables explicativas no cambien, lo que en el contexto de la Economía se denomina <strong><em>ceteris paribus</em></strong>, y que puede que sea imposible de cumplirse. Por ejemplo, el parámetro asociado a <code>Solar.R</code> es, para este modelo de regresión lineal múltiple, 0.0496 menos de la mitad de magnitud que en el caso de regresión simple. Ese sería el cambio medio en las unidades de <code>Ozone</code> para cambios de 1 unidad en <code>Solar.R</code> siempre que <code>Wind</code>, <code>Temp</code> y <code>Month</code> tengan los mismos valores, o, dicho de otro modo, para otro día qué tuviese los mismos valores de <code>Wind</code>, <code>Temp</code> y <code>Month</code>, y cambiase 1 unidad <code>Solar.R</code>. Si es que es factible el cambio de <code>Solar.R</code> con los mismo valores del resto de variables.</p>
<p>Otra lectura que se debe hacer sobre la interpretación de la magnitud del parámetro estimado es que, al ser independiente del resto de valores de las variables, es, a su vez, para cualquier combinación de dichos valores. Por ejemplo, para valores de <code>Wind</code> altos, medios o bajos, combinado con valores de <code>Temp</code> altos, medios o bajos, o para cualquier <code>Month</code> (entre 5 y 9, que es el rango observado).</p>
<blockquote class="blockquote">
<p><strong>Pregunta</strong><br>
¿Cómo interpretaría el valor negativo del término independiente si se trata de la concentración de ozono en partes por billón?</p>
</blockquote>
<p><strong>Bondad de ajuste</strong><br>
La bondad del ajuste de este modelo, ha mejorado mucho comparada con la regresión simple anterior, pasando ahora a un <code>Adjusted R-squared</code> de 0.606.</p>
<p>Si nuestro interés sólo fuese predecir valores de <code>Ozone</code>, este modelo podría servirnos.</p>
<p><strong>Predicción</strong><br>
¿Cómo se pueden obtener predicciones con un modelo de regresión múltiple? Se deben proporcionar valores a cada una de las variables del modelo:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>nuevas.observ <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">Solar.R =</span> <span class="fu">c</span>(<span class="dv">110</span>, <span class="dv">110</span>),</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>                            <span class="at">Wind    =</span> <span class="fu">c</span>(<span class="dv">8</span>, <span class="dv">20</span>), </span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>                            <span class="at">Temp    =</span> <span class="fu">c</span>(<span class="dv">72</span>, <span class="dv">85</span>), </span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>                            <span class="at">Month   =</span> <span class="fu">c</span>(<span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(rlm, <span class="at">newdata =</span> nuevas.observ,</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>        <span class="at">interval =</span> <span class="st">"confidence"</span> )</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       fit       lwr      upr
1 37.62288 30.382618 44.86315
2 22.14613  4.912182 39.38008</code></pre>
</div>
</div>
<section id="predictores-cualitativos" class="level4" data-number="1.4.3.1">
<h4 data-number="1.4.3.1" class="anchored" data-anchor-id="predictores-cualitativos"><span class="header-section-number">1.4.3.1</span> Predictores cualitativos</h4>
<p>El uso de predictores cualitativos debe tratarse de forma diferencial en <code>R</code>. Deben definirse como <em>factor</em>, (<code>factor()</code>). Así, al estimar <code>R</code> los parámetros del modelo donde se incluya dicha variable, generará automáticamente variables ficticias, variables <em>dummys</em>. La función <code>contrasts()</code> permite conocer la codificación que por defecto usa <code>R</code> para dichas variables ficticias (aunque se puede modificar). Para ilustrarlo, redefinimos la variable <code>Month</code> en el conjunto de datos <code>airquality</code></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>airquality<span class="sc">$</span>Month <span class="ot">&lt;-</span> <span class="fu">factor</span> (airquality<span class="sc">$</span>Month) </span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="fu">contrasts</span>(airquality<span class="sc">$</span>Month)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  6 7 8 9
5 0 0 0 0
6 1 0 0 0
7 0 1 0 0
8 0 0 1 0
9 0 0 0 1</code></pre>
</div>
</div>
<p>La salida indica que el valor 5 de <code>Month</code> se toma como valor de referencia (en su fila aparecen todo ceros), y se generan 4 variables <em>dummy</em>, una para cada uno de los meses restantes (del 6 al 9).</p>
<blockquote class="blockquote">
<p>En <code>R</code> las variables definidas como <code>factor</code> toma como referencia la primera categoría al ordenar los valores de la variable, bien alfabéticamente (a, b, c…) o bien numéricamente de menor a mayor, aunque se puede especificar otro orden (véase <a href="#sec-Explotario-Boston" class="quarto-xref"><span>Sección 1.5.1</span></a>).</p>
</blockquote>
<p>Ajustamos de nuevo el modelo de regresión múltiple.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>rlm.cualit <span class="ot">&lt;-</span> <span class="fu">lm</span>(Ozone <span class="sc">~</span> . <span class="sc">-</span> Day, </span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>                 <span class="at">data =</span> airquality)</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(rlm.cualit)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = Ozone ~ . - Day, data = airquality)

Residuals:
    Min      1Q  Median      3Q     Max 
-40.344 -13.495  -3.165  10.399  92.689 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -74.23481   26.10184  -2.844  0.00537 ** 
Solar.R       0.05222    0.02367   2.206  0.02957 *  
Wind         -3.10872    0.66009  -4.710 7.78e-06 ***
Temp          1.87511    0.34073   5.503 2.74e-07 ***
Month6      -14.75895    9.12269  -1.618  0.10876    
Month7       -8.74861    7.82906  -1.117  0.26640    
Month8       -4.19654    8.14693  -0.515  0.60758    
Month9      -15.96728    6.65561  -2.399  0.01823 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 20.72 on 103 degrees of freedom
  (42 observations deleted due to missingness)
Multiple R-squared:  0.6369,    Adjusted R-squared:  0.6122 
F-statistic: 25.81 on 7 and 103 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>Se puede observar que se muestran parámetros para las 4 variables <em>dummy</em> de los 5 valores de <code>Month</code>. Como se ha indicado, el primer valor de la variable (el 5) lo toma como referencia (se podría cambiar si se quiere otro mes de referencia) y genera 4 variables dicotómicas que reflejan el cambio de la categoría de referencia a cada una de ellas. Matemáticamente el modelo que se estima es: <span class="math display">\[\begin{align*}
Ozone = &amp;\beta_0 + \beta_1 Solar.R + \beta_2 Wind + \beta_3 Temp + \\
&amp;\beta_6 Month6 +  \beta_7 Month7 +  \beta_8 Month8 +  \beta_9 Month9 + \epsilon  
\end{align*}\]</span> Así, se entiende ahora mejor la visualización de <code>contrasts()</code> obtenida anteriormente. Cuando <code>Month6</code>, <code>Month7</code>… toman todos el valor 0 la estimación que se obtiene es del mes de mayo. Si la variable dummy <code>Month6</code> toma el valor 1, y las otras 3 toman el valor 0, se obtiene la diferencia media de <code>Ozone</code> respecto al mes de mayo, <em>ceteris paribus</em>. Por lo tanto, que el parámetro asociado a <code>Month6</code> sea negativo implica que, para cualquier combinación fija de valores del resto de variables, en junio disminuye la media de <code>Ozone</code> respecto a mayo (aunque justo este parámetro/cambio no es significativo!).</p>
<blockquote class="blockquote">
<p><strong>Pregunta</strong><br>
¿Como se interpreta ahora el valor del <code>Intercept</code>?<br>
¿Y cómo se explica el valor negativo de <code>Month6</code> a la vista del resumen gráfico que se obtuvo con <code>pairs()</code>?</p>
</blockquote>
</section>
</section>
</section>
<section id="sec-LM-Boston" class="level2" data-number="1.5">
<h2 data-number="1.5" class="anchored" data-anchor-id="sec-LM-Boston"><span class="header-section-number">1.5</span> Caso práctico: <code>Boston</code></h2>
<p>El segundo de los casos prácticos de modelización lineal que se va a tratar en profundidad utiliza los datos <code>Boston</code>, recogidos en varios paquetes, por ejemplo, en <code>ISLR2</code> asociado con el libro: <a href="https://www.statlearning.com" class="uri">https://www.statlearning.com</a>. Los datos recogen valores relacionados con viviendas para <code>506</code> distritos censales de Boston. El estudio de la modelización lineal se puede encontrar en: <a href="https://hastie.su.domains/ISLR2/Labs/Rmarkdown_Notebooks/Ch3-linreg-lab.html" class="uri">https://hastie.su.domains/ISLR2/Labs/Rmarkdown_Notebooks/Ch3-linreg-lab.html</a> y el Rscript asociado en: <a href="https://hastie.su.domains/ISLR2/Labs/R_Labs/Ch3-linreg-lab.R" class="uri">https://hastie.su.domains/ISLR2/Labs/R_Labs/Ch3-linreg-lab.R</a>. De nuevo, aquí se presentan ejemplos ligeramente distintos y con algo más de detalle.</p>
<section id="sec-Explotario-Boston" class="level3" data-number="1.5.1">
<h3 data-number="1.5.1" class="anchored" data-anchor-id="sec-Explotario-Boston"><span class="header-section-number">1.5.1</span> Exploración de los datos</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ISLR2)</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="co">#?Boston #Para obtener más información sobre las variables, unidades, etc. </span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(Boston)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     crim zn indus chas   nox    rm  age    dis rad tax ptratio lstat medv
1 0.00632 18  2.31    0 0.538 6.575 65.2 4.0900   1 296    15.3  4.98 24.0
2 0.02731  0  7.07    0 0.469 6.421 78.9 4.9671   2 242    17.8  9.14 21.6
3 0.02729  0  7.07    0 0.469 7.185 61.1 4.9671   2 242    17.8  4.03 34.7
4 0.03237  0  2.18    0 0.458 6.998 45.8 6.0622   3 222    18.7  2.94 33.4
5 0.06905  0  2.18    0 0.458 7.147 54.2 6.0622   3 222    18.7  5.33 36.2
6 0.02985  0  2.18    0 0.458 6.430 58.7 6.0622   3 222    18.7  5.21 28.7</code></pre>
</div>
</div>
<p>Ahora no parece haber <code>NA</code>s (en el resumen numérico se va a ver que no hay). No obstante, se puede comprobar con:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">is.na</span>(Boston))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0</code></pre>
</div>
</div>
<p><strong>Estructura y resúmenes</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(Boston)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>'data.frame':   506 obs. of  13 variables:
 $ crim   : num  0.00632 0.02731 0.02729 0.03237 0.06905 ...
 $ zn     : num  18 0 0 0 0 0 12.5 12.5 12.5 12.5 ...
 $ indus  : num  2.31 7.07 7.07 2.18 2.18 2.18 7.87 7.87 7.87 7.87 ...
 $ chas   : int  0 0 0 0 0 0 0 0 0 0 ...
 $ nox    : num  0.538 0.469 0.469 0.458 0.458 0.458 0.524 0.524 0.524 0.524 ...
 $ rm     : num  6.58 6.42 7.18 7 7.15 ...
 $ age    : num  65.2 78.9 61.1 45.8 54.2 58.7 66.6 96.1 100 85.9 ...
 $ dis    : num  4.09 4.97 4.97 6.06 6.06 ...
 $ rad    : int  1 2 2 3 3 3 5 5 5 5 ...
 $ tax    : num  296 242 242 222 222 222 311 311 311 311 ...
 $ ptratio: num  15.3 17.8 17.8 18.7 18.7 18.7 15.2 15.2 15.2 15.2 ...
 $ lstat  : num  4.98 9.14 4.03 2.94 5.33 ...
 $ medv   : num  24 21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 ...</code></pre>
</div>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(Boston)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      crim                zn             indus            chas        
 Min.   : 0.00632   Min.   :  0.00   Min.   : 0.46   Min.   :0.00000  
 1st Qu.: 0.08205   1st Qu.:  0.00   1st Qu.: 5.19   1st Qu.:0.00000  
 Median : 0.25651   Median :  0.00   Median : 9.69   Median :0.00000  
 Mean   : 3.61352   Mean   : 11.36   Mean   :11.14   Mean   :0.06917  
 3rd Qu.: 3.67708   3rd Qu.: 12.50   3rd Qu.:18.10   3rd Qu.:0.00000  
 Max.   :88.97620   Max.   :100.00   Max.   :27.74   Max.   :1.00000  
      nox               rm             age              dis        
 Min.   :0.3850   Min.   :3.561   Min.   :  2.90   Min.   : 1.130  
 1st Qu.:0.4490   1st Qu.:5.886   1st Qu.: 45.02   1st Qu.: 2.100  
 Median :0.5380   Median :6.208   Median : 77.50   Median : 3.207  
 Mean   :0.5547   Mean   :6.285   Mean   : 68.57   Mean   : 3.795  
 3rd Qu.:0.6240   3rd Qu.:6.623   3rd Qu.: 94.08   3rd Qu.: 5.188  
 Max.   :0.8710   Max.   :8.780   Max.   :100.00   Max.   :12.127  
      rad              tax           ptratio          lstat      
 Min.   : 1.000   Min.   :187.0   Min.   :12.60   Min.   : 1.73  
 1st Qu.: 4.000   1st Qu.:279.0   1st Qu.:17.40   1st Qu.: 6.95  
 Median : 5.000   Median :330.0   Median :19.05   Median :11.36  
 Mean   : 9.549   Mean   :408.2   Mean   :18.46   Mean   :12.65  
 3rd Qu.:24.000   3rd Qu.:666.0   3rd Qu.:20.20   3rd Qu.:16.95  
 Max.   :24.000   Max.   :711.0   Max.   :22.00   Max.   :37.97  
      medv      
 Min.   : 5.00  
 1st Qu.:17.02  
 Median :21.20  
 Mean   :22.53  
 3rd Qu.:25.00  
 Max.   :50.00  </code></pre>
</div>
</div>
<p>A la vista de la estructura y el resumen numérico, se pueden considerar continuas casi todas las variables (internamente están definidas en <code>R</code> como <code>double</code> o <code>int</code>, para manejar números reales con formato de coma flotante de <em>doble</em> precisión que requieren más espacio en memoria o enteros, respectivamente). Llama la atención el resumen de las variables <code>zn</code>, <code>chas</code> y <code>rad</code>. La variable <code>zn</code> está definida internamente como <code>double</code> porque contiene algunos valores con decimales (y mirando su definición es una proporción). Ahora bien, su mediana es 0, por lo que al menos la mitad de los 506 valores son 0, de hecho el 0 aparece 372 veces. Esto, sin duda tendrá un impacto al considerarlo en los modelos. Por su parte las variables <code>chas</code> y <code>rad</code> tienen formato <code>int</code>, pero acudiendo a su definición, <code>chas</code> es dicotómica (lo que también da sentido que su mediana sea 0 y su media se 0.0692), mientras que <code>rad</code> es un índice, que toma valores entre 1 y 24. Se dejan <code>zn</code> y <code>rad</code> con valores numéricos, pero, para su apropiado manejo en los modelos, es oportuno convertir <code>chas</code> en variable <code>factor</code> de <code>R</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>Boston<span class="sc">$</span>chas <span class="ot">&lt;-</span> <span class="fu">factor</span>(Boston<span class="sc">$</span>chas)</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="fu">contrasts</span>(Boston<span class="sc">$</span>chas)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  1
0 0
1 1</code></pre>
</div>
</div>
<p>Como se puede ver con la función <code>contrasts()</code> en los casos de variable dicotómica sólo se genera una variable <em>dummy</em>, quedando por defecto el valor 0 como valor de referencia. Rizando el rizo, vamos a cambiar la definición del valor de referencia para luego observar su impacto en la modelización.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>Boston<span class="sc">$</span>chas <span class="ot">&lt;-</span> <span class="fu">factor</span>(Boston<span class="sc">$</span>chas, </span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>                      <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>))</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a><span class="fu">contrasts</span>(Boston<span class="sc">$</span>chas)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  0
1 0
0 1</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(Boston, <span class="at">upper.panel =</span> <span class="cn">NULL</span>,</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>      <span class="at">lower.panel =</span> panel.smooth)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Cap1-LM_files/figure-html/unnamed-chunk-30-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>A la vista del resumen gráfico, diagramas de dispersión de pares de variables, casi todas las relaciones entre pares de variables parecen no lineales. Como se puede apreciar, la dicotomía de la variable <code>chas</code> genera diagramas de dispersión muy distintos al resto. Y las variables <code>rad</code> y <code>tax</code> llaman la atención por presentar dos grupos de valores alejados, especialmente <code>rad</code>. También, la variable <code>nox</code> presenta dos grupos de valores pero con menor separación entre grupos.</p>
</section>
<section id="lm-múltiple-1" class="level3" data-number="1.5.2">
<h3 data-number="1.5.2" class="anchored" data-anchor-id="lm-múltiple-1"><span class="header-section-number">1.5.2</span> lm() múltiple</h3>
<p><strong>Modelización y estimación</strong><br>
La variable de interés a modelizar es <code>medv</code> (“median value”: valor mediano de las casas ocupadas por sus propietarios, en $1000s). En el libro ISLR2 utilizan las otras 12 variables explicativas como predictores. Aquí se consideran sólo unas cuantas (ojo con lo que recogen cada una de las variables… ¿<code>age</code>?):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>rlm.Boston <span class="ot">&lt;-</span> <span class="fu">lm</span>(medv <span class="sc">~</span> lstat <span class="sc">+</span> rm <span class="sc">+</span> age <span class="sc">+</span> tax <span class="sc">+</span> chas, <span class="co">#chas definida como factor</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>                 <span class="at">data =</span> Boston)</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(rlm.Boston)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = medv ~ lstat + rm + age + tax + chas, data = Boston)

Residuals:
    Min      1Q  Median      3Q     Max 
-19.358  -3.345  -1.124   1.930  30.073 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  4.323355   3.270507   1.322    0.187    
lstat       -0.588092   0.055117 -10.670  &lt; 2e-16 ***
rm           4.954530   0.440829  11.239  &lt; 2e-16 ***
age          0.014624   0.011379   1.285    0.199    
tax         -0.007009   0.001756  -3.990 7.58e-05 ***
chas0       -3.898106   0.955381  -4.080 5.24e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 5.372 on 500 degrees of freedom
Multiple R-squared:  0.6622,    Adjusted R-squared:  0.6588 
F-statistic:   196 on 5 and 500 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>Se han unificado la modelización y estimación, como se hace generalmente. Posteriormente se realizará el análisis de residuos que permitirá dar validez al modelo considerado.</p>
<p>En este caso, los parámetros asociados a las variables salen significativos, excepto uno. Este hecho, conduce a eliminar dicha variable del modelo, para obtener uno con sólo variables influyentes sobre <code>medv</code>.</p>
<p>La consecuencia de que algunos parámetros no sean significativos también se puede apreciar en sus intervalos de confianza… Los no significativos incluyen el 0.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(rlm.Boston)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                   2.5 %       97.5 %
(Intercept) -2.102274869 10.748985289
lstat       -0.696380539 -0.479802930
rm           4.088424014  5.820635797
age         -0.007732991  0.036981489
tax         -0.010459310 -0.003557925
chas0       -5.775162051 -2.021050701</code></pre>
</div>
</div>
<section id="quitando-predictores" class="level4" data-number="1.5.2.1">
<h4 data-number="1.5.2.1" class="anchored" data-anchor-id="quitando-predictores"><span class="header-section-number">1.5.2.1</span> Quitando predictores</h4>
<p>Como ilustración del proceso iterativo (manual) de modelización, pasamos a estimar un nuevo modelo en el que eliminamos la variable no significativa que se obtuvo en el modelo anterior <code>rlm.Boston</code>, esto es quitando <code>age</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>rlm.BostonModif <span class="ot">&lt;-</span> <span class="fu">lm</span>(medv <span class="sc">~</span> lstat <span class="sc">+</span> rm <span class="sc">+</span> tax <span class="sc">+</span> chas, <span class="at">data =</span> Boston)</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a><span class="co">#Alternativamente, usando la función `update()`.</span></span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a><span class="co">#rlm.BostonModif &lt;- update(rlm.Boston, ~ . - age)</span></span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(rlm.BostonModif)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = medv ~ lstat + rm + tax + chas, data = Boston)

Residuals:
    Min      1Q  Median      3Q     Max 
-19.484  -3.400  -1.158   1.909  30.849 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  4.154797   3.270001   1.271 0.204468    
lstat       -0.554277   0.048462 -11.437  &lt; 2e-16 ***
rm           5.060589   0.433317  11.679  &lt; 2e-16 ***
tax         -0.006412   0.001695  -3.783 0.000174 ***
chas0       -4.076908   0.945811  -4.310 1.96e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 5.376 on 501 degrees of freedom
Multiple R-squared:  0.6611,    Adjusted R-squared:  0.6584 
F-statistic: 244.3 on 4 and 501 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>Ahora el modelo sale con todos los parámetros significativos, con un <code>Adjusted R-squared</code> ligeramente peor. No obstante el <span class="math inline">\(R^2\)</span> ajustado es razonablemente bueno si el objetivo es predecir valores de <code>Ozone</code>.</p>
<blockquote class="blockquote">
<p><strong>Pregunta</strong><br>
¿Cómo quitar varios predictores simultáneamente?<br>
¿Cómo hacer este proceso automáticamente? Véase el <a href="Cap5-Seleccion.html" class="quarto-xref"><span>Capítulo 5</span></a></p>
</blockquote>
<blockquote class="blockquote">
<p><strong>Pregunta</strong><br>
Obtenga este último modelo con la variable <code>chas</code> original (sin convertirla en factor) ¿Qué diferencias observa en la estimación del parámetro asociado a dicha variable?</p>
</blockquote>
<p><strong>Análisis de residuos</strong><br>
Valoremos la adecuación del último modelo examinando sus residuos.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>), <span class="co">#presenta los gráficos en formato 2x2</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">pty =</span> <span class="st">"s"</span>,</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">mex =</span> <span class="fl">0.66</span>,</span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">cex =</span> <span class="fl">0.75</span>)</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(rlm.BostonModif)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Cap1-LM_files/figure-html/unnamed-chunk-33-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<ul>
<li><p>Los gráficos 1 y 3 (Residuals vs Fitted y Scale-Location) reflejan heterocedasticidad y no linealidad.</p></li>
<li><p>En el segundo gráfico (Q-Q Residuals), se observa una clara desviación de la normalidad (marcada por la linea de puntos). Veamos el histograma:</p></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(<span class="fu">residuals</span>(rlm.BostonModif))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Cap1-LM_files/figure-html/unnamed-chunk-34-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>El histograma refleja asimetría por lo que claramente rechazamos la normalidad.</p>
<ul>
<li>Por último en los 4 gráficos de residuos quedan señaladas las observaciones 369 y 373, junto con la 372 que aparece en 3 de los gráficos. Ahora bien, no tienen una distancia de Cook elevada para considerarlas influyentes. De nuevo, parece claro que los problemas comentados (heterocedasticidad, falta de normalidad…) no provienen sólo de esas observaciones.</li>
</ul>
</section>
</section>
<section id="sec-ExtensionesRLM" class="level3" data-number="1.5.3">
<h3 data-number="1.5.3" class="anchored" data-anchor-id="sec-ExtensionesRLM"><span class="header-section-number">1.5.3</span> Extensiones/transformaciones de la regresión múltiple</h3>
<p>El modelo lineal de regresión lineal múltiple permite considerar “constructos” de variables, es decir, considerar productos de dos variables, términos no lineales, etc. El tratamiento de esos casos con <code>R</code> es similar a lo visto hasta ahora, con el inconveniente de enfrentarse a su interpretación. Así, entre los “constructos” más habituales se encuentran:</p>
<ul>
<li><em>Términos de interacción</em>: La sintaxis <code>lstat:age</code> le dice a <code>R</code> que incluya un término de interacción entre <code>lstat</code> y <code>age</code>. La sintaxis <code>lstat * age</code> incluye como predictores simultáneamente <code>lstat</code>, <code>age</code> y la interacción <code>lstat:age</code>, es una abreviatura de <code>lstat + age + lstat:age</code>.</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(medv <span class="sc">~</span> lstat <span class="sc">*</span> age, <span class="at">data =</span> Boston))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = medv ~ lstat * age, data = Boston)

Residuals:
    Min      1Q  Median      3Q     Max 
-15.806  -4.045  -1.333   2.085  27.552 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 36.0885359  1.4698355  24.553  &lt; 2e-16 ***
lstat       -1.3921168  0.1674555  -8.313 8.78e-16 ***
age         -0.0007209  0.0198792  -0.036   0.9711    
lstat:age    0.0041560  0.0018518   2.244   0.0252 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 6.149 on 502 degrees of freedom
Multiple R-squared:  0.5557,    Adjusted R-squared:  0.5531 
F-statistic: 209.3 on 3 and 502 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p><strong>Pregunta</strong><br>
¿Cómo se interpreta que la interacción salga significativa?</p>
</blockquote>
<ul>
<li><em>Transformaciones polinómicas de los predictores</em>: La sintaxis <code>I(lstat^2)</code> introduce en el modelo el predictor cuadrático de <code>lstat</code>.</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>rlm.Boston2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(medv <span class="sc">~</span> lstat <span class="sc">+</span> <span class="fu">I</span>(lstat<span class="sc">^</span><span class="dv">2</span>), <span class="at">data =</span> Boston)</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(rlm.Boston2)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = medv ~ lstat + I(lstat^2), data = Boston)

Residuals:
     Min       1Q   Median       3Q      Max 
-15.2834  -3.8313  -0.5295   2.3095  25.4148 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 42.862007   0.872084   49.15   &lt;2e-16 ***
lstat       -2.332821   0.123803  -18.84   &lt;2e-16 ***
I(lstat^2)   0.043547   0.003745   11.63   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 5.524 on 503 degrees of freedom
Multiple R-squared:  0.6407,    Adjusted R-squared:  0.6393 
F-statistic: 448.5 on 2 and 503 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>El p-valor cercano a cero asociado con el término cuadrático sugiere que, su inclusión, conduce a un modelo mejorado. Pero, obviamente, introduce un problema claro de multicolinealidad, que se puede obviar si el interés en el modelo es por su valor predictivo en lugar de explicativo.</p>
<blockquote class="blockquote">
<p><strong>Pregunta</strong><br>
La función <code>I()</code> es necesaria para el objetivo que se persigue. ¿Qué consecuencias acarrea no aplicar la función <code>I()</code> en la definición del modelo?</p>
</blockquote>
<p>Obviamente se pueden incluir términos cúbicos, etc.: <code>I(variable^3)</code>…, varios a la vez, etc. Pero para un ajuste polinómico, conviene acudir a la función <code>poly()</code>, que, por defecto, ortogonaliza los predictores.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>rlm.Boston6 <span class="ot">&lt;-</span> <span class="fu">lm</span>(medv <span class="sc">~</span> <span class="fu">poly</span>(lstat, <span class="dv">6</span>), <span class="at">data =</span> Boston)</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(rlm.Boston6)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = medv ~ poly(lstat, 6), data = Boston)

Residuals:
     Min       1Q   Median       3Q      Max 
-14.7317  -3.1571  -0.6941   2.0756  26.8994 

Coefficients:
                 Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)       22.5328     0.2317  97.252  &lt; 2e-16 ***
poly(lstat, 6)1 -152.4595     5.2119 -29.252  &lt; 2e-16 ***
poly(lstat, 6)2   64.2272     5.2119  12.323  &lt; 2e-16 ***
poly(lstat, 6)3  -27.0511     5.2119  -5.190 3.06e-07 ***
poly(lstat, 6)4   25.4517     5.2119   4.883 1.41e-06 ***
poly(lstat, 6)5  -19.2524     5.2119  -3.694 0.000245 ***
poly(lstat, 6)6    6.5088     5.2119   1.249 0.212313    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 5.212 on 499 degrees of freedom
Multiple R-squared:  0.6827,    Adjusted R-squared:  0.6789 
F-statistic: 178.9 on 6 and 499 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>La interpretación de esta salida sugiere que el modelo polinómico de orden 5 conduce al mejor ajuste del modelo con un polinomio de la variable <code>lstat</code>.</p>
<ul>
<li><em>Transformaciones logarítmicas</em>: también se pueden aplicar otro tipo de transformaciones sobre los predictores, siempre que sean apropiadas y oportunas.</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(medv <span class="sc">~</span> <span class="fu">log</span>(rm), <span class="at">data =</span> Boston))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = medv ~ log(rm), data = Boston)

Residuals:
    Min      1Q  Median      3Q     Max 
-19.487  -2.875  -0.104   2.837  39.816 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  -76.488      5.028  -15.21   &lt;2e-16 ***
log(rm)       54.055      2.739   19.73   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 6.915 on 504 degrees of freedom
Multiple R-squared:  0.4358,    Adjusted R-squared:  0.4347 
F-statistic: 389.3 on 1 and 504 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
</section>
<section id="comparación-de-modelos-mediante-anova" class="level3" data-number="1.5.4">
<h3 data-number="1.5.4" class="anchored" data-anchor-id="comparación-de-modelos-mediante-anova"><span class="header-section-number">1.5.4</span> Comparación de modelos mediante <code>anova()</code></h3>
<p>Con la función <code>anova()</code> se pueden comparar modelos “jerárquicos”. En los casos expuestos anteriormente, se puede cuantificar hasta qué punto el ajuste cuadrático es superior al ajuste lineal, o que el ajuste de orden 6 no es superior al de orden 5.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>rlm.Boston1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(medv <span class="sc">~</span> lstat, <span class="at">data =</span> Boston)</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(rlm.Boston1, rlm.Boston2)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Model 1: medv ~ lstat
Model 2: medv ~ lstat + I(lstat^2)
  Res.Df   RSS Df Sum of Sq     F    Pr(&gt;F)    
1    504 19472                                 
2    503 15347  1    4125.1 135.2 &lt; 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>rlm.Boston5 <span class="ot">&lt;-</span> <span class="fu">lm</span>(medv <span class="sc">~</span> <span class="fu">poly</span>(lstat, <span class="dv">5</span>), <span class="at">data =</span> Boston)</span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(rlm.Boston5, rlm.Boston6)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Model 1: medv ~ poly(lstat, 5)
Model 2: medv ~ poly(lstat, 6)
  Res.Df   RSS Df Sum of Sq      F Pr(&gt;F)
1    500 13597                           
2    499 13555  1    42.364 1.5596 0.2123</code></pre>
</div>
</div>
<p>En la primera tabla ANOVA se puede ver, en la etiquetada como línea 2, el estadístico F, que recoge la razón de variabilidad explicada por el Model 2 frente al Model 1. Su elevado valor, junto con un p-valor prácticamente nulo, llevan a considerar el modelo cuadrático muy superior al simple. Al lector observador no le debe sorprender este resultado a la vista del diagrama de dispersión entre <code>medv</code> y <code>lstat</code>, que presenta una clara no linealidad.</p>
<p>Por su parte, la segunda tabla ANOVA muestra un resultado bien distinto, con un discreto valor del estadístico F que conduce a rechazar que el polinomio de orden 6 explique mejor la respuesta que el de orden 5. Además se puede comprobar que este p-valor coincide con el p-valor asociado al término de orden 6 estimado por la regresión.</p>
<blockquote class="blockquote">
<p><strong>Pregunta</strong> ¿Qué conclusiones obtiene al comparar los modelos <code>rlm.Boston</code> y <code>rlm.BostonModif</code>?</p>
</blockquote>
</section>
<section id="multicolinealidad-vif" class="level3" data-number="1.5.5">
<h3 data-number="1.5.5" class="anchored" data-anchor-id="multicolinealidad-vif"><span class="header-section-number">1.5.5</span> Multicolinealidad: <code>vif()</code></h3>
<p>El cálculo del <em>factor de inflación de la varianza (VIF)</em> que ayuda a detectar la multicolinealidad (véase <a href="#sec-Multicolinealidad" class="quarto-xref"><span>Sección 1.3.5</span></a>) de cada parámetro se puede obtener con la función <code>vif()</code>, del paquete <code>car</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Cargando paquete requerido: carData</code></pre>
</div>
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="fu">vif</span>(rlm.Boston)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   lstat       rm      age      tax     chas 
2.710812 1.678750 1.795414 1.533240 1.030405 </code></pre>
</div>
</div>
<p>Para estos datos, la mayoría de los VIF son bajos o moderados.</p>
<blockquote class="blockquote">
<p><strong>Regla de decisión práctica</strong>: No preocuparse de la multicolinealidad si <code>vif &lt; 5</code>, incluso <code>vif &lt; 10</code>.</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>Pregunta</strong><br>
¿Cómo salen los VIF de la regresión múltiple con los datos <code>airquality</code>?</p>
</blockquote>
<p>Veamos un ejemplo claro de colinealidad:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="fu">vif</span>(rlm.Boston2)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     lstat I(lstat^2) 
  12.93657   12.93657 </code></pre>
</div>
</div>
<blockquote class="blockquote">
<p><strong>Pregunta</strong><br>
¿Qué interpretación tiene que los VIF sean iguales?</p>
</blockquote>
<p>Vamos a generar un caso con alta colinealidad:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(pi)</span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a>Boston<span class="sc">$</span>sum <span class="ot">&lt;-</span> Boston<span class="sc">$</span>lstat<span class="sc">/</span><span class="dv">2</span> <span class="sc">+</span> Boston<span class="sc">$</span>rm <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="fu">length</span>(Boston<span class="sc">$</span>lstat))</span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a>rlm.BostonColine <span class="ot">&lt;-</span> <span class="fu">lm</span>(medv <span class="sc">~</span> lstat <span class="sc">+</span> rm <span class="sc">+</span> tax <span class="sc">+</span> chas <span class="sc">+</span> sum, </span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a>                       <span class="at">data =</span> Boston)</span>
<span id="cb81-5"><a href="#cb81-5" aria-hidden="true" tabindex="-1"></a><span class="fu">vif</span>(rlm.BostonColine)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    lstat        rm       tax      chas       sum 
13.189150  1.988231  1.430875  1.008564 10.209699 </code></pre>
</div>
</div>
<blockquote class="blockquote">
<p><strong>Pregunta</strong><br>
¿Qué interpretación tienen ahora los VIF?</p>
</blockquote>
</section>
</section>
<section id="resumen" class="level2" data-number="1.6">
<h2 data-number="1.6" class="anchored" data-anchor-id="resumen"><span class="header-section-number">1.6</span> Resumen</h2>
<p>Este capítulo se dedica a los <em>modelos lineales de regresión</em> que permiten explicar una variable cuantitativa (respuesta) en función de una o más variables explicativas. Se estudia tanto el caso más sencillo, la regresión lineal simple (una sola variable explicativa), como su generalización, la regresión múltiple (varias variables explicativas). El capítulo se completa con dos casos prácticos de modelización, utilizando <code>R</code> y los conjuntos de datos <code>airquality</code> y <code>Boston</code>.</p>
<p>Los modelos de regresión se basan en una estructura algebraica, lineal en los parámetros, más un término de error aleatorio que recoge la variabilidad no explicada por la estructura.</p>
<p>Para estimar los parámetros del modelo se utilizan estimadores de <em>mínimos cuadrados</em>, que buscan minimizar la suma de los cuadrados de los residuos y que, bajo normalidad, coinciden con los obtenidos por el método de <em>máxima verosimilitud</em>. En el documento se proporcionan las fórmulas y el procedimiento para su obtención.</p>
<p>El modelo se sustenta en unos <em>supuestos</em> que se han verificar. El análisis de residuos es clave para validar (o no) tales supuestos. Se utilizan gráficos como el de residuos frente a valores ajustados para homocedasticidad y linealidad y el Q-Q plot para normalidad. También se aplican contrastes como Shapiro-Wilk, Durbin-Watson, Bartlett y Levene. Algunas observaciones pueden tener gran impacto en el modelo. Mediante la medición de su <em>leverage</em> y su <em>distancia de Cook</em> se evalúa cuánto cambia el modelo al eliminar tal observación.</p>
<p>Gracias al conocimiento de las distribuciones en el muestreo de los estimadores, se pueden realizar contrastes de hipótesis y construir intervalos de confianza, que permiten interpretar el modelo.</p>
<p>La calidad del modelo se evalúa con el coeficiente de determinación <span class="math inline">\(R^2\)</span>, que mide la proporción de variabilidad explicada por el modelo. En regresión simple, coincide con el cuadrado del coeficiente de correlación. En regresión múltiple, se utiliza el <span class="math inline">\(R^2\)</span> corregido que penaliza los modelos por el número de variables.</p>
<p>Cuando los supuestos no se cumplen, pueden aplicarse transformaciones a las variables. La familia Box-Cox ofrece opciones como logaritmo, raíz cuadrada o inversa. Estas transformaciones pueden mejorar la linealidad o la homocedasticidad, aunque afectan la interpretación de los parámetros.</p>
<p>Al plantear regresiones lineales múltiples, se introducen retos como la selección de variables, la multicolinealidad y la interpretabilidad. Se usan herramientas como el VIF para detectar redundancia entre variables y técnicas como ANOVA para comparar modelos.</p>
<p>En los casos prácticos se muestra cómo definir modelos con <code>lm()</code>, interpretar los resultados obtenidos con <code>summary()</code>, obtener intervalos con <code>confint()</code> y realizar predicciones con <code>predict()</code>. También se exploran gráficos de diagnóstico y medidas de influencia.</p>
</section>
<section id="bibliografía" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="bibliografía">Bibliografía</h2>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-CDRlm" class="csl-entry" role="listitem">
Casero-Alonso, Víctor, y María Durbán. 2024. <span>«Modelización lineal»</span>. En <em>Fundamentos de Ciencia de Datos con R</em>. McGraw Hill. <a href="https://cdr-book.github.io/cap-lm.html">https://cdr-book.github.io/cap-lm.html</a>.
</div>
<div id="ref-Faraway" class="csl-entry" role="listitem">
Faraway, Julian J. 2004. <em>Linear Models with <span>R</span></em>. Chapman &amp;amp; Hall/CRC.
</div>
<div id="ref-CDR" class="csl-entry" role="listitem">
Fernández-Avilés, Gema, y José-María Montero. 2024. <em>Fundamentos de Ciencia de Datos con R</em>. McGraw Hill. <a href="https://cdr-book.github.io/index.html">https://cdr-book.github.io/index.html</a>.
</div>
<div id="ref-Pena2002" class="csl-entry" role="listitem">
Peña, Daniel. 2002. <em>Regresión y diseño de experimentos</em>. Alianza Editorial.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiado");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiado");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./index.html" class="pagination-link" aria-label="Prefacio">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Prefacio</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./Cap2-DoE.html" class="pagination-link" aria-label="Diseño de experimentos">
        <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Diseño de experimentos</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>